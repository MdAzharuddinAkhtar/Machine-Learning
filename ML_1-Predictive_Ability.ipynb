{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dd3acfb-8232-4286-a5af-ebf664d39b23",
   "metadata": {},
   "source": [
    "# Machine Learning: Measuring the predictive ability of a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b61bac7-af2f-42ca-a7ee-03c0267ad891",
   "metadata": {},
   "source": [
    "## Mean Squared Error (MSE): Theory and Application in Machine Learning\n",
    "\n",
    "### 1. Introduction\n",
    "\n",
    "**Mean Squared Error (MSE)** is a widely used loss function in regression tasks. It measures the average of the squares of the errors — that is, the average squared difference between the **predicted values** and the **actual values**.\n",
    "\n",
    "MSE is particularly important in **supervised learning**, especially for evaluating and optimizing **regression models**.\n",
    "\n",
    "\n",
    "\n",
    "### 2. Mathematical Definition\n",
    "\n",
    "Given a dataset with \\( $n$ \\) observations, where:\n",
    "- \\( $y_i$ \\) is the **true/actual value**,\n",
    "- \\( $\\hat{y}_i$ \\) is the **predicted value** from the model,\n",
    "\n",
    "the Mean Squared Error is defined as:\n",
    "\n",
    "\\\n",
    "$\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$\n",
    "\n",
    "\n",
    "Where:\n",
    "-  $(y_i - \\hat{y}_i)$  is the **error (residual)** for observation \\( $i$ \\),\n",
    "- Squaring the error penalizes **larger deviations** more heavily.\n",
    "\n",
    "\n",
    "\n",
    "### 3. Interpretation\n",
    "\n",
    "- **Lower MSE** indicates better model performance (i.e., predictions are closer to actual values).\n",
    "- **Higher MSE** means larger errors, indicating poor model fit.\n",
    "\n",
    "The squaring ensures that negative and positive errors do not cancel each other out.\n",
    "\n",
    "\n",
    "\n",
    "### 4. MSE in Machine Learning Context\n",
    "\n",
    "In **machine learning**, MSE is commonly used as a **loss function** in regression models, guiding the optimization of model parameters. It is particularly used in algorithms such as:\n",
    "\n",
    "- **Linear Regression**\n",
    "- **Ridge/Lasso Regression**\n",
    "- **Neural Networks (regression output)**\n",
    "- **Gradient Boosting Machines (GBM)**\n",
    "- **Support Vector Regression (SVR)**\n",
    "\n",
    "\n",
    "\n",
    "### 5. Example: Linear Regression\n",
    "\n",
    "Consider a simple linear regression model:\n",
    "\n",
    "\\$[\n",
    "\\hat{y}_i = \\beta_0 + \\beta_1 x_i\n",
    "\\]$\n",
    "\n",
    "The **objective** is to find \\( $\\beta_0$, $\\beta_1$ \\) that minimize the MSE:\n",
    "\n",
    "\\\n",
    "$\\min_{\\beta_0, \\beta_1} \\left\\{ \\frac{1}{n} \\sum_{i=1}^{n} \\left( y_i - (\\beta_0 + \\beta_1 x_i) \\right)^2 \\right\\}$\n",
    "\n",
    "\n",
    "This is the **least squares** criterion, and minimizing it gives the **best linear unbiased estimator (BLUE)** under classical assumptions.\n",
    "\n",
    "\n",
    "\n",
    "### 6. MSE vs. Other Metrics\n",
    "\n",
    "| Metric | Formula | Notes |\n",
    "|--------|---------|-------|\n",
    "| MSE | \\( $\\frac{1}{n} \\sum (y_i - \\hat{y}_i)^2$ \\) | Penalizes larger errors more |\n",
    "| MAE (Mean Absolute Error) | \\( $\\frac{1}{n} \\sum |y_i - \\hat{y}_i|$ \\) | Less sensitive to outliers |\n",
    "| RMSE (Root MSE) | \\( $\\sqrt{\\text{MSE}}$ \\) | Same unit as the target variable |\n",
    "| R² (Coefficient of Determination) | \\( $1 - \\frac{SS_{res}}{SS_{tot}}$ \\) | Relative measure of fit |\n",
    "\n",
    "\n",
    "\n",
    "### 7. Applications of MSE\n",
    "\n",
    "- **Model Evaluation**: Compare models by their average prediction error.\n",
    "- **Hyperparameter Tuning**: MSE is minimized during cross-validation.\n",
    "- **Gradient Descent**: MSE provides a differentiable loss for optimization.\n",
    "- **Forecasting**: Used in time-series forecasting accuracy.\n",
    "\n",
    "\n",
    "\n",
    "### 8. Limitations of MSE\n",
    "\n",
    "- **Sensitive to Outliers**: Squaring errors exaggerates the impact of large deviations.\n",
    "- **Not Interpretable in Original Units**: Since errors are squared, MSE is in squared units.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dc29ee-9a8a-4e32-be0b-8b05e1b7ee33",
   "metadata": {},
   "source": [
    "**Simulation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a240616-7f58-4a96-9238-7787d860e8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.2875\n"
     ]
    }
   ],
   "source": [
    "# Python Example\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_true = [3.0, -0.5, 2.0, 7.0]\n",
    "y_pred = [2.5, 0.0, 2.1, 7.8]\n",
    "\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc44a47-a856-43f9-adf5-0982e5dfb32e",
   "metadata": {},
   "source": [
    "**Example from NSS dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3138e9d-6984-4c16-8a87-8e3049b7f2f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sector</th>\n",
       "      <th>District</th>\n",
       "      <th>Household_Size</th>\n",
       "      <th>NIC_2008_five_digit_code</th>\n",
       "      <th>NCO_2004_three_digit_code</th>\n",
       "      <th>Household_Type</th>\n",
       "      <th>Religion</th>\n",
       "      <th>Social_Group</th>\n",
       "      <th>Latrine</th>\n",
       "      <th>Drinking_Water</th>\n",
       "      <th>...</th>\n",
       "      <th>In_Public</th>\n",
       "      <th>In_Private</th>\n",
       "      <th>Hospitalisation</th>\n",
       "      <th>In_Save_Income</th>\n",
       "      <th>In_Borrowing</th>\n",
       "      <th>In_Sale_Assets</th>\n",
       "      <th>In_Friend_Cont</th>\n",
       "      <th>In_OtherSource</th>\n",
       "      <th>In_NetMedicalExp</th>\n",
       "      <th>In_Pro_NetMedicalExp_CE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>49224</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>07100</td>\n",
       "      <td>931</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>56101</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12,620.00</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>07100</td>\n",
       "      <td>811</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>360.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>07100</td>\n",
       "      <td>931</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9,910.00</td>\n",
       "      <td>1.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sector  District  Household_Size NIC_2008_five_digit_code  \\\n",
       "0       2        23               3                    49224   \n",
       "1       2        23               4                    07100   \n",
       "2       2        23               6                    56101   \n",
       "3       2        23               5                    07100   \n",
       "4       2        23               2                    07100   \n",
       "\n",
       "  NCO_2004_three_digit_code  Household_Type  Religion  Social_Group  Latrine  \\\n",
       "0                       121               1         1             9        2   \n",
       "1                       931               3         1             1        2   \n",
       "2                       121               1         1             9        1   \n",
       "3                       811               2         1             1        1   \n",
       "4                       931               3         1             1        2   \n",
       "\n",
       "   Drinking_Water  ...  In_Public  In_Private  Hospitalisation  \\\n",
       "0               4  ...       0.00        0.00             0.00   \n",
       "1               4  ...       0.00        0.00             0.00   \n",
       "2               4  ...       0.00        1.00             1.00   \n",
       "3               4  ...       1.00        0.00             1.00   \n",
       "4               4  ...       0.00        1.00             1.00   \n",
       "\n",
       "   In_Save_Income  In_Borrowing  In_Sale_Assets  In_Friend_Cont  \\\n",
       "0            0.00          0.00            0.00            0.00   \n",
       "1            0.00          0.00            0.00            0.00   \n",
       "2            1.00          0.00            0.00            0.00   \n",
       "3            1.00          0.00            0.00            0.00   \n",
       "4            1.00          1.00            0.00            0.00   \n",
       "\n",
       "   In_OtherSource  In_NetMedicalExp  In_Pro_NetMedicalExp_CE  \n",
       "0            0.00              0.00                     0.00  \n",
       "1            0.00              0.00                     0.00  \n",
       "2            0.00         12,620.00                     0.39  \n",
       "3            0.00            360.00                     0.01  \n",
       "4            0.00          9,910.00                     1.65  \n",
       "\n",
       "[5 rows x 73 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.float_format', '{:,.2f}'.format)\n",
    "\n",
    "# Provide the full path to your .dta file\n",
    "file_path = r\"D:\\Altaf\\Impact of Insurance on Catastrophic Risk Exposure\\Impact of formal insurance on informal insurance\\Final Dataset 2017.dta\"\n",
    "\n",
    "# Load the data using pandas\n",
    "df = pd.read_stata(file_path)\n",
    "\n",
    "# View first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c68beda-97a1-40c2-a6cc-8b988cfe4b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sector',\n",
       " 'District',\n",
       " 'Household_Size',\n",
       " 'NIC_2008_five_digit_code',\n",
       " 'NCO_2004_three_digit_code',\n",
       " 'Household_Type',\n",
       " 'Religion',\n",
       " 'Social_Group',\n",
       " 'Latrine',\n",
       " 'Drinking_Water',\n",
       " 'Cooking_Energy',\n",
       " 'Insurance_Premium',\n",
       " 'Consumption_Expenditure',\n",
       " 'Child',\n",
       " 'Adult',\n",
       " 'MPCE_Euro',\n",
       " 'State',\n",
       " 'CatMPCE',\n",
       " 'Gender',\n",
       " 'Age',\n",
       " 'Marital_Status',\n",
       " 'Education',\n",
       " 'No_Insurance',\n",
       " 'No_In_PublicIns',\n",
       " 'No_In_PrivateIns',\n",
       " 'Time',\n",
       " 'HHID',\n",
       " 'comb_wt',\n",
       " 'Out_Reimbersment',\n",
       " 'Out_MedicalExp',\n",
       " 'Out_TotMedicalExp',\n",
       " 'No_Out_Public',\n",
       " 'No_Out_Private',\n",
       " 'Out_LossIncome',\n",
       " 'No_Out_Save_Income',\n",
       " 'No_Out_Borrowing',\n",
       " 'No_Out_Sale_Assets',\n",
       " 'No_Out_Friend_Cont',\n",
       " 'No_Out_OtherSource',\n",
       " 'In_MedicalExp',\n",
       " 'In_TotMedicalExp',\n",
       " 'In_Reimbersment',\n",
       " 'In_LossIncome',\n",
       " 'No_In_Save_Income',\n",
       " 'No_In_Borrowing',\n",
       " 'No_In_Sale_Assets',\n",
       " 'No_In_Friend_Cont',\n",
       " 'No_In_OtherSource',\n",
       " 'No_In_Public',\n",
       " 'No_In_Private',\n",
       " 'No_Hospitalisation',\n",
       " 'No_OPD',\n",
       " 'No_Ailment',\n",
       " 'Out_Public',\n",
       " 'Out_Private',\n",
       " 'OPD',\n",
       " 'Out_Save_Income',\n",
       " 'Out_Borrowing',\n",
       " 'Out_Sale_Assets',\n",
       " 'Out_Friend_Cont',\n",
       " 'Out_OtherSource',\n",
       " 'Out_NetMedicalExp',\n",
       " 'Out_Pro_NetMedicalExp_CE',\n",
       " 'In_Public',\n",
       " 'In_Private',\n",
       " 'Hospitalisation',\n",
       " 'In_Save_Income',\n",
       " 'In_Borrowing',\n",
       " 'In_Sale_Assets',\n",
       " 'In_Friend_Cont',\n",
       " 'In_OtherSource',\n",
       " 'In_NetMedicalExp',\n",
       " 'In_Pro_NetMedicalExp_CE']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all variable names\n",
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24c37f00-789b-4df6-b303-dcaaeda40114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     113,823.00\n",
       "mean       13,641.70\n",
       "std        52,852.39\n",
       "min             0.00\n",
       "25%             0.00\n",
       "50%             0.00\n",
       "75%         8,800.00\n",
       "max     5,051,700.00\n",
       "Name: In_TotMedicalExp, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary statistics\n",
    "df['In_TotMedicalExp'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77dd0d71-3559-4cd8-83de-5ec99fade789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) of total inpatient medical expenditure: 2793351102.40\n"
     ]
    }
   ],
   "source": [
    "# Variable of interest: 'In_TotMedicalExp'\n",
    "# Drop missing values\n",
    "y = df['In_TotMedicalExp'].dropna()\n",
    "\n",
    "# Use the mean as a simple prediction\n",
    "y_pred = np.full_like(y, y.mean())\n",
    "\n",
    "# Calculate MSE\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "print(f\"Mean Squared Error (MSE) of total inpatient medical expenditure: {mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4fefa95-192d-4fe4-be3e-482b8b8e515a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(y, bins=100, kde=True)\n",
    "plt.title(\"Distribution of In_TotMedicalExp\")\n",
    "plt.xlabel(\"Inpatient Medical Expenditure\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9e363c-4c6d-408d-83b3-db914814e93d",
   "metadata": {},
   "source": [
    "The Mean Squared Error (MSE) looks very large because the variable **In_TotMedicalExp** has very large values, with a maximum of over $5 million$ and a standard deviation of over $52,000$. The MSE seems huge because:\n",
    "\n",
    "- The variable is right-skewed: Many zero or low values, but a few extremely high ones (outliers).\n",
    "\n",
    "- The MSE is sensitive to large deviations: It squares the difference between actual and predicted values, which amplifies the effect of outliers.\n",
    "\n",
    "- Using the mean as a prediction for all values, which may be a poor predictor in the presence of skewness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2d1db9c-0c8b-4c50-b397-6714d527ab56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-transformed MSE: 21.71\n"
     ]
    }
   ],
   "source": [
    "# Use log-transformation (for interpretation or modeling)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "y_log = np.log1p(y)  # log(1 + y) to handle 0 values\n",
    "y_log_pred = np.full_like(y_log, y_log.mean())\n",
    "mse_log = mean_squared_error(y_log, y_log_pred)\n",
    "print(f\"Log-transformed MSE: {mse_log:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94257dfa-82e2-42c5-93d0-149d51dc746f",
   "metadata": {},
   "source": [
    "## Information criteria and related penalty measures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7cfb7b-a635-49df-948d-6181aafb3bb1",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "In regression and statistical modeling, multiple models may fit the data. To select the **best** model among candidates, we use **model selection criteria** that balance:\n",
    "- **Goodness-of-fit**\n",
    "- **Model complexity (penalizing overfitting)**\n",
    "\n",
    "The key metrics covered here are:\n",
    "- Akaike Information Criterion (**$AIC$**)\n",
    "- Bayesian Information Criterion (**$BIC$**)\n",
    "- Mallow’s (**$C_p$**)\n",
    "- Coefficient of Determination (**$R^2$** and adjusted **$R^2$**)\n",
    "\n",
    "\n",
    "\n",
    "### 1. Akaike Information Criterion (AIC)\n",
    "\n",
    "#### Definition:\n",
    "AIC estimates the **information loss** from using a model to represent the process that generated the data. It penalizes models with more parameters.\n",
    "\n",
    "\\\n",
    "$\\text{AIC} = -2 \\log(\\hat{L}) + 2k$\n",
    "\n",
    "\n",
    "Where:\n",
    "- \\( $\\hat{L}$ \\): Maximized value of the likelihood function\n",
    "- \\( $k$ \\): Number of parameters (including the intercept)\n",
    "\n",
    "#### Interpretation:\n",
    "- **Lower AIC** is better.\n",
    "- Balances model fit and complexity.\n",
    "- Applicable to both nested and non-nested models.\n",
    "\n",
    "For linear regression with Gaussian errors:\n",
    "\n",
    "\\\n",
    "$\\text{AIC} = n \\log\\left(\\frac{\\text{RSS}}{n}\\right) + 2k$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 2. Bayesian Information Criterion (BIC)\n",
    "\n",
    "#### Definition:\n",
    "BIC is derived from a Bayesian framework. It imposes a **harsher penalty** for model complexity than AIC.\n",
    "\n",
    "\\\n",
    "$\\text{BIC} = -2 \\log(\\hat{L}) + k \\log(n)$\n",
    "\n",
    "\n",
    "Where:\n",
    "- \\( $n$ \\): Number of observations\n",
    "- \\( $k$ \\): Number of parameters\n",
    "\n",
    "### Interpretation:\n",
    "- **Lower BIC** is better.\n",
    "- Tends to favor simpler models as sample size increases.\n",
    "\n",
    "In linear regression:\n",
    "\n",
    "\\\n",
    "$\\text{BIC} = n \\log\\left(\\frac{\\text{RSS}}{n}\\right) + k \\log(n)$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 3. Mallow’s \\( $C_p$ \\)\n",
    "\n",
    "#### Definition:\n",
    "Mallow’s \\( $C_p$ \\) is a criterion for model selection in **linear regression**, comparing a subset model to the full model.\n",
    "\n",
    "\\\n",
    "$C_p = \\frac{1}{\\hat{\\sigma}^2} \\left[ \\text{RSS}_p + 2p \\hat{\\sigma}^2 \\right]$\n",
    "\n",
    "\n",
    "Where:\n",
    "- \\( $\\text{RSS}_p$ \\): Residual Sum of Squares for model with \\( $p$ \\) predictors\n",
    "- \\( $\\hat{\\sigma}^2$ \\): Estimate of variance from full model\n",
    "- \\( $p$ \\): Number of predictors in the model\n",
    "\n",
    "### Simplified version:\n",
    "\n",
    "\\\n",
    "$C_p = \\frac{\\text{RSS}_p}{\\hat{\\sigma}^2} - n + 2p$\n",
    "\n",
    "\n",
    "#### Interpretation:\n",
    "- **Models with \\( $C_p \\approx p$ \\)** are preferred.\n",
    "- Helps identify models with minimum bias and acceptable variance.\n",
    "\n",
    "\n",
    "\n",
    "### 4. Coefficient of Determination \\( $R^2$ \\)\n",
    "\n",
    "### Definition:\n",
    "\\( $R^2$ \\) measures the proportion of variance in the dependent variable explained by the independent variables.\n",
    "\n",
    "\\\n",
    "$R^2 = 1 - \\frac{\\text{RSS}}{\\text{TSS}} = \\frac{\\text{ESS}}{\\text{TSS}}$\n",
    "\n",
    "\n",
    "Where:\n",
    "- \\( $\\text{TSS} = \\sum (y_i - \\bar{y})^2$ \\): Total Sum of Squares\n",
    "- \\( $\\text{ESS} = \\sum (\\hat{y}_i - \\bar{y})^2$ \\): Explained Sum of Squares\n",
    "- \\( $\\text{RSS} = \\sum (y_i - \\hat{y}_i)^2$ \\): Residual Sum of Squares\n",
    "\n",
    "#### AttributeError Interpretation:\n",
    "- \\( $R^2$ in $[0, 1]$ \\)\n",
    "- Closer to 1 indicates better fit.\n",
    "- **Limitation**: Always increases with more predictors, even if they add no value.\n",
    "\n",
    "\n",
    "\n",
    "### 5. Adjusted \\( $R^2$ \\)\n",
    "\n",
    "#### Definition:\n",
    "Adjusted \\( $R^2$ \\) penalizes for adding variables that don’t improve the model significantly.\n",
    "\n",
    "\\\n",
    "$R^2_{\\text{adj}} = 1 - \\left( \\frac{(1 - R^2)(n - 1)}{n - k - 1} \\right)$\n",
    "\n",
    "\n",
    "Where:\n",
    "- \\( $n$ \\): Number of observations\n",
    "- \\( $k$ \\): Number of predictors\n",
    "\n",
    "#### Interpretation:\n",
    "- Can decrease if unnecessary predictors are added.\n",
    "- More reliable for comparing models with different numbers of predictors.\n",
    "\n",
    "\n",
    "\n",
    "### 6. Summary: Comparison Table\n",
    "\n",
    "| Metric | Penalizes Complexity? | Prefer Higher or Lower? | Comments |\n",
    "|--------|------------------------|--------------------------|----------|\n",
    "| AIC | ✅ Yes (mild) | Lower | Good for prediction |\n",
    "| BIC | ✅ Yes (strong) | Lower | Prefers simpler models |\n",
    "| Mallow’s \\( $C_p$ \\) | ✅ Yes | \\( $C_p$ $\\approx p$ \\) | Useful in linear regression |\n",
    "| \\( $R^2$ \\) | ❌ No | Higher | Can be misleading |\n",
    "| Adjusted \\( $R^2$ \\) | ✅ Yes | Higher | Better for model comparison |\n",
    "\n",
    "\n",
    "\n",
    "### 7. Conclusion\n",
    "\n",
    "Information criteria and penalty-based metrics are essential tools for model selection in machine learning and econometrics. While \\( $R^2$ \\) is intuitive, it lacks penalization for complexity. Criteria like AIC, BIC, and \\( $C_p$ \\) provide a more robust balance between **fit** and **parsimony**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874d20ea-eb3a-4441-a4d5-231df1eead71",
   "metadata": {},
   "source": [
    "**Simulation**\n",
    "\n",
    "**More generally, different penalties may favor different models.**. Below is some of the few examples using simulated dataset and real dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "22ce5645-b5aa-4e68-9834-53fdac9f3c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIC (full model): 262.92205749595854\n",
      "AIC (partial model): 261.0303015368499\n",
      "BIC (full model): 273.3427382399109\n",
      "BIC (partial model): 268.84581209481416\n",
      "R^2 (full model): 0.8805084747875472\n",
      "Adjusted R^2 (full model): 0.8767743646246581\n",
      "R^2 (partial model): 0.8803790623041196\n",
      "Adjusted R^2 (partial model): 0.8779126512176065\n",
      "Mallow's Cp (partial model): 2.104\n",
      "Mallow's Cp (full model): 4.0\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Sample dataset\n",
    "np.random.seed(42)\n",
    "n = 100\n",
    "X1 = np.random.normal(0, 1, n)\n",
    "X2 = np.random.normal(0, 1, n)\n",
    "X3 = np.random.normal(0, 1, n)  # Irrelevant variable\n",
    "\n",
    "# True relationship: y depends only on X1 and X2\n",
    "y = 3 + 2 * X1 - 1.5 * X2 + np.random.normal(0, 1, n)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({'X1': X1, 'X2': X2, 'X3': X3, 'y': y})\n",
    "\n",
    "# Add constant term\n",
    "X_full = sm.add_constant(df[['X1', 'X2', 'X3']])\n",
    "X_partial = sm.add_constant(df[['X1', 'X2']])\n",
    "y = df['y']\n",
    "\n",
    "# Fit full model (including irrelevant X3)\n",
    "model_full = sm.OLS(y, X_full).fit()\n",
    "\n",
    "# Fit partial model (excluding X3)\n",
    "model_partial = sm.OLS(y, X_partial).fit()\n",
    "\n",
    "# === AIC ===\n",
    "print(\"AIC (full model):\", model_full.aic)\n",
    "print(\"AIC (partial model):\", model_partial.aic)\n",
    "\n",
    "# === BIC ===\n",
    "print(\"BIC (full model):\", model_full.bic)\n",
    "print(\"BIC (partial model):\", model_partial.bic)\n",
    "\n",
    "# === R^2 and Adjusted R^2 ===\n",
    "print(\"R^2 (full model):\", model_full.rsquared)\n",
    "print(\"Adjusted R^2 (full model):\", model_full.rsquared_adj)\n",
    "print(\"R^2 (partial model):\", model_partial.rsquared)\n",
    "print(\"Adjusted R^2 (partial model):\", model_partial.rsquared_adj)\n",
    "\n",
    "# === Mallow's Cp ===\n",
    "# Cp = RSSp / sigma^2 - n + 2p\n",
    "def mallows_cp(model_subset, model_full, n):\n",
    "    RSS_p = np.sum(model_subset.resid ** 2)\n",
    "    sigma2_full = np.sum(model_full.resid ** 2) / (n - model_full.df_model - 1)\n",
    "    p = model_subset.df_model + 1  # +1 for intercept\n",
    "    Cp = RSS_p / sigma2_full - n + 2 * p\n",
    "    return Cp\n",
    "\n",
    "cp_partial = mallows_cp(model_partial, model_full, n)\n",
    "cp_full = mallows_cp(model_full, model_full, n)\n",
    "\n",
    "print(\"Mallow's Cp (partial model):\", round(cp_partial, 3))\n",
    "print(\"Mallow's Cp (full model):\", round(cp_full, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625b50ad-38df-48c4-92d9-d3350d7458a6",
   "metadata": {},
   "source": [
    "**Example from NSS Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef351ebc-5e36-42aa-865a-5dd1911b6a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIC (full model): 2794785.6768826284\n",
      "AIC (partial model): 2797160.0632651052\n",
      "BIC (full model): 2794824.246482185\n",
      "BIC (partial model): 2797188.990464773\n",
      "R^2 (full model): 0.03407429519612393\n",
      "Adjusted R^2 (full model): 0.034048835676057765\n",
      "R^2 (partial model): 0.013695794960299601\n",
      "Adjusted R^2 (partial model): 0.013678464013101688\n",
      "Mallow's Cp (partial model): 2403.2825280513644\n",
      "Mallow's Cp (full model): 4.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "from statsmodels.tools.eval_measures import aic, bic\n",
    "\n",
    "df = pd.read_stata(r\"D:\\Altaf\\Impact of Insurance on Catastrophic Risk Exposure\\Impact of formal insurance on informal insurance\\Final Dataset 2017.dta\")\n",
    "\n",
    "# Define dependent variable\n",
    "y = df['In_TotMedicalExp']\n",
    "\n",
    "# Full model: all relevant predictors\n",
    "X_full = df[['Age', 'Household_Size', 'MPCE_Euro']]  # Replace with your full model variables\n",
    "\n",
    "# Partial model: subset of predictors\n",
    "X_partial = df[['Age', 'Household_Size']]  # Replace with your reduced model variables\n",
    "\n",
    "# Add constant\n",
    "X_full = sm.add_constant(X_full)\n",
    "X_partial = sm.add_constant(X_partial)\n",
    "\n",
    "model_full = sm.OLS(y, X_full).fit()\n",
    "model_partial = sm.OLS(y, X_partial).fit()\n",
    "\n",
    "# AIC & BIC\n",
    "print(\"AIC (full model):\", model_full.aic)\n",
    "print(\"AIC (partial model):\", model_partial.aic)\n",
    "print(\"BIC (full model):\", model_full.bic)\n",
    "print(\"BIC (partial model):\", model_partial.bic)\n",
    "\n",
    "# R-squared & Adjusted R-squared\n",
    "print(\"R^2 (full model):\", model_full.rsquared)\n",
    "print(\"Adjusted R^2 (full model):\", model_full.rsquared_adj)\n",
    "print(\"R^2 (partial model):\", model_partial.rsquared)\n",
    "print(\"Adjusted R^2 (partial model):\", model_partial.rsquared_adj)\n",
    "\n",
    "n = len(y)\n",
    "p_full = model_full.df_model + 1  # include intercept\n",
    "p_partial = model_partial.df_model + 1\n",
    "\n",
    "# RSS\n",
    "rss_partial = np.sum(model_partial.resid ** 2)\n",
    "sigma_squared = np.sum(model_full.resid ** 2) / model_full.df_resid\n",
    "\n",
    "# Mallow's Cp\n",
    "cp_partial = rss_partial / sigma_squared - (n - 2 * p_partial)\n",
    "cp_full = p_full  # for full model, Cp ≈ p\n",
    "\n",
    "print(\"Mallow's Cp (partial model):\", cp_partial)\n",
    "print(\"Mallow's Cp (full model):\", cp_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a52810c-b4e7-419c-bb9b-780d32f3279a",
   "metadata": {},
   "source": [
    "**Simulation**\n",
    "\n",
    "**To enable comparison of all eight possible models that are linear in parameters and regressors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf3d0fcb-4fb8-4757-a344-88fa2fed18b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All Models Sorted by Cp:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Variables</th>\n",
       "      <th>AIC</th>\n",
       "      <th>BIC</th>\n",
       "      <th>R2</th>\n",
       "      <th>Adj R2</th>\n",
       "      <th>Mallow's Cp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xlist8</td>\n",
       "      <td>x1, x2, x3</td>\n",
       "      <td>262.92</td>\n",
       "      <td>273.34</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.91</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xlist5</td>\n",
       "      <td>x1, x2</td>\n",
       "      <td>378.88</td>\n",
       "      <td>386.69</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.72</td>\n",
       "      <td>218.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xlist7</td>\n",
       "      <td>x1, x3</td>\n",
       "      <td>394.16</td>\n",
       "      <td>401.98</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>269.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xlist6</td>\n",
       "      <td>x2, x3</td>\n",
       "      <td>409.71</td>\n",
       "      <td>417.53</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.62</td>\n",
       "      <td>331.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xlist2</td>\n",
       "      <td>x1</td>\n",
       "      <td>439.72</td>\n",
       "      <td>444.93</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>489.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xlist3</td>\n",
       "      <td>x2</td>\n",
       "      <td>466.48</td>\n",
       "      <td>471.70</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>669.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>xlist4</td>\n",
       "      <td>x3</td>\n",
       "      <td>468.83</td>\n",
       "      <td>474.04</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.31</td>\n",
       "      <td>687.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>xlist1</td>\n",
       "      <td>Intercept only</td>\n",
       "      <td>505.22</td>\n",
       "      <td>507.83</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1,051.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model       Variables    AIC    BIC    R2  Adj R2  Mallow's Cp\n",
       "0  xlist8      x1, x2, x3 262.92 273.34  0.92    0.91         4.00\n",
       "1  xlist5          x1, x2 378.88 386.69  0.73    0.72       218.28\n",
       "2  xlist7          x1, x3 394.16 401.98  0.68    0.68       269.86\n",
       "3  xlist6          x2, x3 409.71 417.53  0.63    0.62       331.06\n",
       "4  xlist2              x1 439.72 444.93  0.49    0.49       489.44\n",
       "5  xlist3              x2 466.48 471.70  0.33    0.33       669.08\n",
       "6  xlist4              x3 468.83 474.04  0.32    0.31       687.23\n",
       "7  xlist1  Intercept only 505.22 507.83 -0.00   -0.00     1,051.78"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import itertools\n",
    "\n",
    "# Seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Simulate data\n",
    "n = 100\n",
    "x1 = np.random.normal(0, 1, n)\n",
    "x2 = np.random.normal(0, 1, n)\n",
    "x3 = np.random.normal(0, 1, n)\n",
    "\n",
    "# True model: y depends on all three\n",
    "y = 5 + 2*x1 - 1.5*x2 + 1.2*x3 + np.random.normal(0, 1, n)\n",
    "\n",
    "# Combine into DataFrame\n",
    "df = pd.DataFrame({'x1': x1, 'x2': x2, 'x3': x3, 'y': y})\n",
    "\n",
    "# Define all 8 x-lists from the image\n",
    "xlists = [\n",
    "    [],         # xlist1\n",
    "    ['x1'],     # xlist2\n",
    "    ['x2'],     # xlist3\n",
    "    ['x3'],     # xlist4\n",
    "    ['x1','x2'],# xlist5\n",
    "    ['x2','x3'],# xlist6\n",
    "    ['x1','x3'],# xlist7\n",
    "    ['x1','x2','x3']  # xlist8 (full model)\n",
    "]\n",
    "\n",
    "# Fit full model first (for Mallow's Cp)\n",
    "X_full = sm.add_constant(df[['x1','x2','x3']])\n",
    "model_full = sm.OLS(df['y'], X_full).fit()\n",
    "sigma2_full = np.sum(model_full.resid**2) / model_full.df_resid\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "for i, xlist in enumerate(xlists, 1):\n",
    "    if xlist:\n",
    "        X = sm.add_constant(df[xlist])\n",
    "    else:\n",
    "        X = sm.add_constant(pd.DataFrame(index=df.index))  # Intercept only\n",
    "    \n",
    "    model = sm.OLS(df['y'], X).fit()\n",
    "    rss = np.sum(model.resid**2)\n",
    "    p = model.df_model + 1  # Number of parameters including intercept\n",
    "    n = df.shape[0]\n",
    "    \n",
    "    cp = rss / sigma2_full - n + 2*p\n",
    "    \n",
    "    results.append({\n",
    "        'Model': f'xlist{i}',\n",
    "        'Variables': ', '.join(xlist) if xlist else 'Intercept only',\n",
    "        'AIC': model.aic,\n",
    "        'BIC': model.bic,\n",
    "        'R2': model.rsquared,\n",
    "        'Adj R2': model.rsquared_adj,\n",
    "        \"Mallow's Cp\": cp\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame and sort by AIC\n",
    "results_df = pd.DataFrame(results)\n",
    "sorted_results = results_df.sort_values('AIC').reset_index(drop=True)\n",
    "\n",
    "# Display sorted results\n",
    "print(\"\\nAll Models Sorted by Cp:\")\n",
    "display(sorted_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3352c4a7-13e3-475c-8ff9-d1959ed718b5",
   "metadata": {},
   "source": [
    "**Example from NSS Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9823d2c-7934-411b-a41b-b6ee872e4303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All Models Sorted by Cp:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>AIC</th>\n",
       "      <th>BIC</th>\n",
       "      <th>R2</th>\n",
       "      <th>Adj_R2</th>\n",
       "      <th>Cp</th>\n",
       "      <th>Num_Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Age + MPCE_Euro</td>\n",
       "      <td>2,794,785.06</td>\n",
       "      <td>2,794,813.98</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>3.38</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age + Household_Size + MPCE_Euro</td>\n",
       "      <td>2,794,785.68</td>\n",
       "      <td>2,794,824.25</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Household_Size + MPCE_Euro</td>\n",
       "      <td>2,796,105.00</td>\n",
       "      <td>2,796,133.92</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1,330.97</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MPCE_Euro</td>\n",
       "      <td>2,796,233.52</td>\n",
       "      <td>2,796,252.81</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1,461.09</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Age + Household_Size</td>\n",
       "      <td>2,797,160.06</td>\n",
       "      <td>2,797,188.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2,403.28</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Age</td>\n",
       "      <td>2,797,243.02</td>\n",
       "      <td>2,797,262.31</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2,488.07</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Intercept Only</td>\n",
       "      <td>2,798,725.73</td>\n",
       "      <td>2,798,735.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4,013.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Household_Size</td>\n",
       "      <td>2,798,726.19</td>\n",
       "      <td>2,798,745.47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4,013.51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Model          AIC          BIC   R2  Adj_R2  \\\n",
       "0                   Age + MPCE_Euro 2,794,785.06 2,794,813.98 0.03    0.03   \n",
       "1  Age + Household_Size + MPCE_Euro 2,794,785.68 2,794,824.25 0.03    0.03   \n",
       "2        Household_Size + MPCE_Euro 2,796,105.00 2,796,133.92 0.02    0.02   \n",
       "3                         MPCE_Euro 2,796,233.52 2,796,252.81 0.02    0.02   \n",
       "4              Age + Household_Size 2,797,160.06 2,797,188.99 0.01    0.01   \n",
       "5                               Age 2,797,243.02 2,797,262.31 0.01    0.01   \n",
       "6                    Intercept Only 2,798,725.73 2,798,735.38 0.00    0.00   \n",
       "7                    Household_Size 2,798,726.19 2,798,745.47 0.00    0.00   \n",
       "\n",
       "        Cp  Num_Params  \n",
       "0     3.38           3  \n",
       "1     4.00           4  \n",
       "2 1,330.97           3  \n",
       "3 1,461.09           2  \n",
       "4 2,403.28           3  \n",
       "5 2,488.07           2  \n",
       "6 4,013.11           1  \n",
       "7 4,013.51           2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from itertools import combinations\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_stata(r\"D:\\Altaf\\Impact of Insurance on Catastrophic Risk Exposure\\Impact of formal insurance on informal insurance\\Final Dataset 2017.dta\")\n",
    "\n",
    "# Select relevant variables and drop missing values\n",
    "model_data = df[['In_TotMedicalExp', 'Age', 'Household_Size', 'MPCE_Euro']].dropna()\n",
    "y = model_data['In_TotMedicalExp']\n",
    "X = model_data[['Age', 'Household_Size', 'MPCE_Euro']]\n",
    "n = len(y)  # Number of observations\n",
    "\n",
    "# Generate all combinations of independent variables\n",
    "variables = ['Age', 'Household_Size', 'MPCE_Euro']\n",
    "models = []\n",
    "for k in range(0, len(variables) + 1):\n",
    "    for combo in combinations(variables, k):\n",
    "        models.append(list(combo))\n",
    "\n",
    "# Fit full model for Cp calculation\n",
    "X_full = sm.add_constant(X[list(variables)])\n",
    "model_full = sm.OLS(y, X_full).fit()\n",
    "sigma2_full = model_full.mse_resid  # σ² from full model\n",
    "\n",
    "# Initialize results storage\n",
    "results = []\n",
    "\n",
    "# Evaluate all models\n",
    "for model_vars in models:\n",
    "    if not model_vars:  # Intercept-only model\n",
    "        X_design = sm.add_constant(np.ones((n, 1)))\n",
    "    else:\n",
    "        X_design = sm.add_constant(X[list(model_vars)])\n",
    "    \n",
    "    model = sm.OLS(y, X_design).fit()\n",
    "    p = X_design.shape[1]  # Number of parameters (including intercept)\n",
    "    rss = model.ssr  # Residual sum of squares\n",
    "    \n",
    "    # Calculate metrics\n",
    "    aic = model.aic\n",
    "    bic = model.bic\n",
    "    r2 = model.rsquared\n",
    "    adj_r2 = model.rsquared_adj\n",
    "    cp = (rss / sigma2_full) - n + 2 * p  # Mallows' Cp\n",
    "    \n",
    "    results.append({\n",
    "        'Model': ' + '.join(model_vars) if model_vars else \"Intercept Only\",\n",
    "        'AIC': round(aic, 3),\n",
    "        'BIC': round(bic, 3),\n",
    "        'R2': round(r2, 4),\n",
    "        'Adj_R2': round(adj_r2, 4),\n",
    "        'Cp': round(cp, 3),\n",
    "        'Num_Params': p\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame and sort by AIC\n",
    "results_df = pd.DataFrame(results)\n",
    "sorted_results = results_df.sort_values('AIC').reset_index(drop=True)\n",
    "\n",
    "# Display sorted results\n",
    "print(\"\\nAll Models Sorted by Cp:\")\n",
    "display(sorted_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53576d72-e947-4960-8f9c-b2cc9d3d96d5",
   "metadata": {},
   "source": [
    "## The splitsample\n",
    "\n",
    "In the preceding example, model estimation and assessment of fit were conducted using the same dataset, which may lead to overfitting and optimistic evaluations of model performance. In contrast, cross-validation (CV) addresses this limitation by partitioning the data into two distinct subsets: a training set used for model estimation and a test (or holdout / validation) set used to evaluate the model's predictive performance. This methodological approach enhances the generalizability of the model and is applicable to a wide variety of model types and loss functions, extending beyond the mean squared error (MSE)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dba11c-d4db-48aa-ab38-6ecf467e2d43",
   "metadata": {},
   "source": [
    "**Simulation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b582377-5500-4906-a0e4-c223c58ad9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Comparison Using Single-Split Cross-Validation (80% Train / 20% Test)\n",
      "\n",
      "Model    Variables               Train MSE     Test MSE\n",
      "-------------------------------------------------------\n",
      "xlist1    Intercept only             9.0593       8.6469\n",
      "xlist2    x1                         4.7858       3.7803\n",
      "xlist3    x2                         6.0986       5.4881\n",
      "xlist4    x3                         6.4463       4.9119\n",
      "xlist5    x1, x2                     2.6876       1.5215\n",
      "xlist6    x2, x3                     3.4715       2.7655\n",
      "xlist7    x1, x3                     3.0045       2.2226\n",
      "xlist8    x1, x2, x3                 0.8163       0.5146\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Simulate dataset\n",
    "n = 100\n",
    "x1 = np.random.normal(0, 1, n)\n",
    "x2 = np.random.normal(0, 1, n)\n",
    "x3 = np.random.normal(0, 1, n)\n",
    "y = 5 + 2*x1 - 1.5*x2 + 1.2*x3 + np.random.normal(0, 1, n)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({'x1': x1, 'x2': x2, 'x3': x3, 'y': y})\n",
    "\n",
    "# Define xlists\n",
    "xlists = [\n",
    "    [],             # xlist1\n",
    "    ['x1'],         # xlist2\n",
    "    ['x2'],         # xlist3\n",
    "    ['x3'],         # xlist4\n",
    "    ['x1', 'x2'],   # xlist5\n",
    "    ['x2', 'x3'],   # xlist6\n",
    "    ['x1', 'x3'],   # xlist7\n",
    "    ['x1', 'x2', 'x3']  # xlist8\n",
    "]\n",
    "\n",
    "# Train-test split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Model Comparison Using Single-Split Cross-Validation (80% Train / 20% Test)\\n\")\n",
    "print(f\"{'Model':<8} {'Variables':<20} {'Train MSE':>12} {'Test MSE':>12}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "for i, xlist in enumerate(xlists, 1):\n",
    "    model = LinearRegression()\n",
    "    \n",
    "    if xlist:\n",
    "        X_train = train_df[xlist]\n",
    "        X_test = test_df[xlist]\n",
    "    else:\n",
    "        # Intercept-only model\n",
    "        X_train = np.ones((len(train_df), 1))\n",
    "        X_test = np.ones((len(test_df), 1))\n",
    "    \n",
    "    y_train = train_df['y']\n",
    "    y_test = test_df['y']\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "    \n",
    "    vars_label = ', '.join(xlist) if xlist else 'Intercept only'\n",
    "    print(f\"xlist{i:<4} {vars_label:<20} {mse_train:12.4f} {mse_test:12.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf813032-1089-4b46-8b67-d4076b0e8f0c",
   "metadata": {},
   "source": [
    "#### Interpretation (Based on Output)\n",
    "\n",
    "- xlist8 (full model) performs best with the lowest test MSE, as expected since it includes all true predictors.\n",
    "\n",
    "- Simpler models like xlist2, xlist5, and xlist7 may still perform well if they include the most influential variables.\n",
    "\n",
    "- xlist1 (intercept only) performs worst — confirming the need for predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bfadc2-b941-4ca3-872b-99a56d683c65",
   "metadata": {},
   "source": [
    "**Example from NSS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "356770e8-6d10-4579-8dcd-cc165e33d760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Comparison Using Single-Split Cross-Validation (80% Train / 20% Test)\n",
      "Model    Variables                              Train MSE     Test MSE\n",
      "----------------------------------------------------------------------\n",
      "Model 1  Intercept only                      2943349659.1846 2193421004.2919\n",
      "Model 2  Age                                 2910081588.5061 2164878573.7610\n",
      "Model 3  Household_Size                      2974490433.9293 2220749335.8529\n",
      "Model 4  MPCE_Euro                           2882147182.3154 2151848881.6209\n",
      "Model 5  Age, Household_Size                 2905680736.6150 2161959279.6602\n",
      "Model 6  Age, MPCE_Euro                      2882138919.8876 2151840402.1987\n",
      "Model 7  Household_Size, MPCE_Euro           2882147125.3525 2151848819.0004\n",
      "Model 8  Age, Household_Size, MPCE_Euro      2882138863.6767 2151840342.6026\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from itertools import combinations\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_stata(r\"D:\\Altaf\\Impact of Insurance on Catastrophic Risk Exposure\\Impact of formal insurance on informal insurance\\Final Dataset 2017.dta\")\n",
    "\n",
    "# Prepare data\n",
    "model_data = df[['In_TotMedicalExp', 'Age', 'Household_Size', 'MPCE_Euro']].dropna()\n",
    "y = model_data['In_TotMedicalExp']\n",
    "X = model_data[['Age', 'Household_Size', 'MPCE_Euro']]\n",
    "\n",
    "# Generate all combinations of independent variables\n",
    "variables = list(X.columns)\n",
    "models = []\n",
    "for k in range(0, len(variables) + 1):\n",
    "    for combo in combinations(variables, k):\n",
    "        models.append(list(combo))\n",
    "\n",
    "# Train-test split (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Model Comparison Using Single-Split Cross-Validation (80% Train / 20% Test)\")\n",
    "print(f\"{'Model':<8} {'Variables':<35} {'Train MSE':>12} {'Test MSE':>12}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, model_vars in enumerate(models, 1):\n",
    "    # Prepare training data\n",
    "    if model_vars:\n",
    "        X_train_sub = X_train[list(model_vars)]\n",
    "        X_test_sub = X_test[list(model_vars)]\n",
    "        vars_label = ', '.join(model_vars)\n",
    "    else:  # Intercept-only model\n",
    "        X_train_sub = pd.DataFrame(np.ones(len(X_train)), columns=['Intercept'])\n",
    "        X_test_sub = pd.DataFrame(np.ones(len(X_test)), columns=['Intercept'])\n",
    "        vars_label = 'Intercept only'\n",
    "    \n",
    "    # Create and fit model\n",
    "    model = LinearRegression(fit_intercept=False)\n",
    "    model.fit(X_train_sub, y_train)\n",
    "    \n",
    "    # Calculate MSE\n",
    "    train_pred = model.predict(X_train_sub)\n",
    "    test_pred = model.predict(X_test_sub)\n",
    "    train_mse = mean_squared_error(y_train, train_pred)\n",
    "    test_mse = mean_squared_error(y_test, test_pred)\n",
    "    \n",
    "    results.append({\n",
    "        'Model': f'Model {i}',\n",
    "        'Variables': vars_label,\n",
    "        'Train MSE': train_mse,\n",
    "        'Test MSE': test_mse\n",
    "    })\n",
    "    \n",
    "    print(f\"Model {i:<2} {vars_label:<35} {train_mse:12.4f} {test_mse:12.4f}\")\n",
    "\n",
    "# Create sorted DataFrame by Test MSE\n",
    "results_df = pd.DataFrame(results).sort_values('Test MSE').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f9b17d-0572-4619-98c4-9083f04b8847",
   "metadata": {},
   "source": [
    "**To identify the best fit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3cb3ff8c-be59-415b-a291-50162f49f178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Models Sorted by Test MSE (Best First):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Variables</th>\n",
       "      <th>Train MSE</th>\n",
       "      <th>Test MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model 8</td>\n",
       "      <td>Age, Household_Size, MPCE_Euro</td>\n",
       "      <td>2,882,138,863.68</td>\n",
       "      <td>2,151,840,342.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Model 6</td>\n",
       "      <td>Age, MPCE_Euro</td>\n",
       "      <td>2,882,138,919.89</td>\n",
       "      <td>2,151,840,402.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Model 7</td>\n",
       "      <td>Household_Size, MPCE_Euro</td>\n",
       "      <td>2,882,147,125.35</td>\n",
       "      <td>2,151,848,819.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Model 4</td>\n",
       "      <td>MPCE_Euro</td>\n",
       "      <td>2,882,147,182.32</td>\n",
       "      <td>2,151,848,881.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Model 5</td>\n",
       "      <td>Age, Household_Size</td>\n",
       "      <td>2,905,680,736.61</td>\n",
       "      <td>2,161,959,279.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Model 2</td>\n",
       "      <td>Age</td>\n",
       "      <td>2,910,081,588.51</td>\n",
       "      <td>2,164,878,573.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Model 1</td>\n",
       "      <td>Intercept only</td>\n",
       "      <td>2,943,349,659.18</td>\n",
       "      <td>2,193,421,004.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Model 3</td>\n",
       "      <td>Household_Size</td>\n",
       "      <td>2,974,490,433.93</td>\n",
       "      <td>2,220,749,335.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model                       Variables        Train MSE         Test MSE\n",
       "0  Model 8  Age, Household_Size, MPCE_Euro 2,882,138,863.68 2,151,840,342.60\n",
       "1  Model 6                  Age, MPCE_Euro 2,882,138,919.89 2,151,840,402.20\n",
       "2  Model 7       Household_Size, MPCE_Euro 2,882,147,125.35 2,151,848,819.00\n",
       "3  Model 4                       MPCE_Euro 2,882,147,182.32 2,151,848,881.62\n",
       "4  Model 5             Age, Household_Size 2,905,680,736.61 2,161,959,279.66\n",
       "5  Model 2                             Age 2,910,081,588.51 2,164,878,573.76\n",
       "6  Model 1                  Intercept only 2,943,349,659.18 2,193,421,004.29\n",
       "7  Model 3                  Household_Size 2,974,490,433.93 2,220,749,335.85"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nModels Sorted by Test MSE (Best First):\")\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150984ba-6d82-4b29-9777-7f68d5cde7fd",
   "metadata": {},
   "source": [
    "### K-fold Cross Validation\n",
    "The results obtained from single-split (or hold-out) validation are inherently sensitive to the manner in which the data is partitioned. Specifically, variations in random seed or sampling strategy can lead to different training-test splits, which in turn may cause fluctuations in model performance metrics such as out-of-sample mean squared error (MSE). For instance, in the current context, using different random splits may result in a model other than the one using x1 alone yielding the lowest test MSE.\n",
    "\n",
    "To mitigate this dependence on a single split, $𝑘$-fold cross-validation (CV) is widely employed. This approach systematically partitions the data into $𝑘$ mutually exclusive and approximately equal-sized subsets, referred to as folds. Each fold serves as a test set exactly once, while the remaining $𝑘−1$ folds collectively form the training set. The model is iteratively trained and evaluated across all $𝑘$ folds, and the overall predictive performance is assessed by averaging the evaluation metric (e.g., MSE) across all iterations.\n",
    "\n",
    "This procedure reduces the variance associated with model evaluation and provides a more robust estimate of generalization error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab9b576-8333-4d15-9120-ac9d155b4d31",
   "metadata": {},
   "source": [
    "#### Formula: Cross-Validated MSE\n",
    "\n",
    "Let the dataset be partitioned into \\( $k$ \\) folds. For each fold \\( $i = 1, 2, ..., k$ \\):\n",
    "\n",
    "- Let \\( $\\mathcal{T}_{-i}$ \\) denote the training set (all folds except fold \\( $i$ \\))  \n",
    "- Let \\( $\\mathcal{V}_i$ \\) denote the validation (test) set (fold \\( $i$ \\))  \n",
    "- Let \\( $\\hat{f}^{(-i)}(\\cdot)$ \\) be the model trained on \\( $\\mathcal{T}_{-i}$ \\)  \n",
    "\n",
    "Then, the **cross-validated Mean Squared Error (MSE)** is defined as:\n",
    "\n",
    "\n",
    "$\\text{MSE}_{CV} = \\frac{1}{k} \\sum_{i=1}^{k} \\frac{1}{n_i} \\sum_{j \\in \\mathcal{V}_i} \\left( y_j - \\hat{f}^{(-i)}(x_j) \\right)^2$\n",
    "\n",
    "\n",
    "Where:\n",
    "- \\( $n_i$ \\) is the number of observations in fold \\( $i$ \\)  \n",
    "- \\( $y_j$ \\) is the true outcome for observation \\( $j$ \\)  \n",
    "- \\( $\\hat{f}^{(-i)}(x_j)$ \\) is the predicted value from the model trained without fold \\( $i$ \\)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b08751c-ea8b-4433-90d4-5fb4a4078ff5",
   "metadata": {},
   "source": [
    "As the number of folds in cross-validation increases, the size of each training set correspondingly grows, resulting in a **reduction in bias** of the estimated prediction error. However, this comes at a trade-off: with more folds, the **overlap among training sets increases**, leading to **greater correlation in the resulting test set predictions**. This correlation contributes to an **increase in the variance** of the estimate of the expected prediction error, denoted as $\\mathbb{E}[(y_0 - \\hat{y}_0)^2]$.\n",
    "\n",
    "Empirical and theoretical evidence suggest that choosing **\\( $k = 5$ \\)** or **\\( $k = 10$ \\)** in \\( $k$ \\)-fold cross-validation typically provides a favorable **bias-variance trade-off**, making them the most commonly used values in practice. For example, use k = 5 and obtain the MSE for each  fold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3a12ea-3262-452e-9b23-8da92ec72f8c",
   "metadata": {},
   "source": [
    "**Simulation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6f1df57d-9c8f-4492-b6cb-9369d81f3fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 MSE: 0.5146\n",
      "Fold 2 MSE: 0.8069\n",
      "Fold 3 MSE: 0.8980\n",
      "Fold 4 MSE: 0.6456\n",
      "Fold 5 MSE: 1.3430\n",
      "\n",
      "Average 5-Fold CV MSE: 0.8416\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Simulate data\n",
    "n = 100\n",
    "x1 = np.random.normal(0, 1, n)\n",
    "x2 = np.random.normal(0, 1, n)\n",
    "x3 = np.random.normal(0, 1, n)\n",
    "y = 5 + 2*x1 - 1.5*x2 + 1.2*x3 + np.random.normal(0, 1, n)\n",
    "\n",
    "# Create full DataFrame\n",
    "df = pd.DataFrame({'x1': x1, 'x2': x2, 'x3': x3, 'y': y})\n",
    "X = df[['x1', 'x2', 'x3']].values\n",
    "y = df['y'].values\n",
    "\n",
    "# Initialize model and KFold\n",
    "model = LinearRegression()\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Store MSEs\n",
    "mse_folds = []\n",
    "\n",
    "# Perform 5-fold CV\n",
    "fold = 1\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_folds.append(mse)\n",
    "    \n",
    "    print(f\"Fold {fold} MSE: {mse:.4f}\")\n",
    "    fold += 1\n",
    "\n",
    "# Average MSE\n",
    "avg_mse = np.mean(mse_folds)\n",
    "print(f\"\\nAverage 5-Fold CV MSE: {avg_mse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7892637e-576e-4ea3-8e33-63f7244e8e22",
   "metadata": {},
   "source": [
    "#### Interpretation:\n",
    "\n",
    "- Each fold provides an estimate of the model's generalization error (out-of-sample MSE).\n",
    "\n",
    "- The variation in MSE across folds is relatively small, suggesting stable predictive performance.\n",
    "\n",
    "- The average MSE (~1.01) is a robust estimate of how well the full model (with x1, x2, x3) would perform on unseen data.\n",
    "\n",
    "- This average MSE is more reliable than a single-split MSE, as it reduces the impact of any one particular train-test split.\n",
    "\n",
    "- Given the data is simulated using the full model, it's expected that this model performs well across all folds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b4a659-cb7d-4e0d-bfd3-ae24641f65a1",
   "metadata": {},
   "source": [
    "**Example from NSS Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b746f61f-0002-4b81-a6de-d582b24849cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-Fold Cross-Validation Results for All Models\n",
      "Model    Variables                           Avg Train MSE Avg Test MSE Test MSE Std\n",
      "-------------------------------------------------------------------------------------\n",
      "Model 1  Intercept only                      2793346007.2411 2793394861.2272 579964697.8972\n",
      "Model 2  Age                                 2761014863.8667 2761089644.6592 577687814.7197\n",
      "Model 3  Household_Size                      2823728148.0368 2823758196.5639 581903772.7196\n",
      "Model 4  MPCE_Euro                           2736033347.8566 2736179360.3437 567292182.3646\n",
      "Model 5  Age, Household_Size                 2756891757.3790 2757111233.6256 576958828.5947\n",
      "Model 6  Age, MPCE_Euro                      2736025037.1728 2736171050.5307 567292250.5605\n",
      "Model 7  Household_Size, MPCE_Euro           2736033289.5348 2736179302.2171 567292185.6532\n",
      "Model 8  Age, Household_Size, MPCE_Euro      2736024978.7912 2736170992.4012 567292250.6678\n",
      "\n",
      "Best Model: Model 8 (Age, Household_Size, MPCE_Euro)\n",
      "Average Test MSE: 2736170992.4012 ± 567292250.6678\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Variables</th>\n",
       "      <th>Avg Train MSE</th>\n",
       "      <th>Avg Test MSE</th>\n",
       "      <th>Test MSE Std</th>\n",
       "      <th>Fold Test MSEs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model 8</td>\n",
       "      <td>Age, Household_Size, MPCE_Euro</td>\n",
       "      <td>2,736,024,978.79</td>\n",
       "      <td>2,736,170,992.40</td>\n",
       "      <td>567,292,250.67</td>\n",
       "      <td>[2151840342.603073, 3790704069.922354, 2422770...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Model 6</td>\n",
       "      <td>Age, MPCE_Euro</td>\n",
       "      <td>2,736,025,037.17</td>\n",
       "      <td>2,736,171,050.53</td>\n",
       "      <td>567,292,250.56</td>\n",
       "      <td>[2151840401.2394824, 3790704128.751542, 242277...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Model 7</td>\n",
       "      <td>Household_Size, MPCE_Euro</td>\n",
       "      <td>2,736,033,289.53</td>\n",
       "      <td>2,736,179,302.22</td>\n",
       "      <td>567,292,185.65</td>\n",
       "      <td>[2151848813.441727, 3790712167.5211277, 242277...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Model 4</td>\n",
       "      <td>MPCE_Euro</td>\n",
       "      <td>2,736,033,347.86</td>\n",
       "      <td>2,736,179,360.34</td>\n",
       "      <td>567,292,182.36</td>\n",
       "      <td>[2151848875.08473, 3790712219.882701, 24227785...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Model 5</td>\n",
       "      <td>Age, Household_Size</td>\n",
       "      <td>2,756,891,757.38</td>\n",
       "      <td>2,757,111,233.63</td>\n",
       "      <td>576,958,828.59</td>\n",
       "      <td>[2161959279.660212, 3829884094.0453672, 243668...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Model 2</td>\n",
       "      <td>Age</td>\n",
       "      <td>2,761,014,863.87</td>\n",
       "      <td>2,761,089,644.66</td>\n",
       "      <td>577,687,814.72</td>\n",
       "      <td>[2164878573.76095, 3834591284.7595186, 2441272...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Model 1</td>\n",
       "      <td>Intercept only</td>\n",
       "      <td>2,793,346,007.24</td>\n",
       "      <td>2,793,394,861.23</td>\n",
       "      <td>579,964,697.90</td>\n",
       "      <td>[2193421004.2919292, 3869464680.2694287, 24701...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Model 3</td>\n",
       "      <td>Household_Size</td>\n",
       "      <td>2,823,728,148.04</td>\n",
       "      <td>2,823,758,196.56</td>\n",
       "      <td>581,903,772.72</td>\n",
       "      <td>[2220749335.852858, 3902265716.4567704, 250328...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model                       Variables    Avg Train MSE     Avg Test MSE  \\\n",
       "0  Model 8  Age, Household_Size, MPCE_Euro 2,736,024,978.79 2,736,170,992.40   \n",
       "1  Model 6                  Age, MPCE_Euro 2,736,025,037.17 2,736,171,050.53   \n",
       "2  Model 7       Household_Size, MPCE_Euro 2,736,033,289.53 2,736,179,302.22   \n",
       "3  Model 4                       MPCE_Euro 2,736,033,347.86 2,736,179,360.34   \n",
       "4  Model 5             Age, Household_Size 2,756,891,757.38 2,757,111,233.63   \n",
       "5  Model 2                             Age 2,761,014,863.87 2,761,089,644.66   \n",
       "6  Model 1                  Intercept only 2,793,346,007.24 2,793,394,861.23   \n",
       "7  Model 3                  Household_Size 2,823,728,148.04 2,823,758,196.56   \n",
       "\n",
       "    Test MSE Std                                     Fold Test MSEs  \n",
       "0 567,292,250.67  [2151840342.603073, 3790704069.922354, 2422770...  \n",
       "1 567,292,250.56  [2151840401.2394824, 3790704128.751542, 242277...  \n",
       "2 567,292,185.65  [2151848813.441727, 3790712167.5211277, 242277...  \n",
       "3 567,292,182.36  [2151848875.08473, 3790712219.882701, 24227785...  \n",
       "4 576,958,828.59  [2161959279.660212, 3829884094.0453672, 243668...  \n",
       "5 577,687,814.72  [2164878573.76095, 3834591284.7595186, 2441272...  \n",
       "6 579,964,697.90  [2193421004.2919292, 3869464680.2694287, 24701...  \n",
       "7 581,903,772.72  [2220749335.852858, 3902265716.4567704, 250328...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from itertools import combinations\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_stata(r\"D:\\Altaf\\Impact of Insurance on Catastrophic Risk Exposure\\Impact of formal insurance on informal insurance\\Final Dataset 2017.dta\")\n",
    "\n",
    "# Prepare data\n",
    "model_data = df[['In_TotMedicalExp', 'Age', 'Household_Size', 'MPCE_Euro']].dropna()\n",
    "y = model_data['In_TotMedicalExp'].values\n",
    "X = model_data[['Age', 'Household_Size', 'MPCE_Euro']]\n",
    "\n",
    "# Generate all combinations of independent variables\n",
    "variables = list(X.columns)\n",
    "models = []\n",
    "for k in range(0, len(variables) + 1):\n",
    "    for combo in combinations(variables, k):\n",
    "        models.append(list(combo))\n",
    "\n",
    "# Set up KFold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "results = []\n",
    "\n",
    "print(\"5-Fold Cross-Validation Results for All Models\")\n",
    "print(f\"{'Model':<8} {'Variables':<35} {'Avg Train MSE':>12} {'Avg Test MSE':>12} {'Test MSE Std':>12}\")\n",
    "print(\"-\" * 85)\n",
    "\n",
    "# Evaluate each model\n",
    "for i, model_vars in enumerate(models, 1):\n",
    "    # Prepare variable names for display\n",
    "    vars_label = ', '.join(model_vars) if model_vars else 'Intercept only'\n",
    "    \n",
    "    # Initialize storage for fold results\n",
    "    train_mses = []\n",
    "    test_mses = []\n",
    "    \n",
    "    # Cross-validation loop\n",
    "    for fold, (train_index, test_index) in enumerate(kf.split(X), 1):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Prepare model data\n",
    "        if model_vars:\n",
    "            X_train_sub = X_train[list(model_vars)]\n",
    "            X_test_sub = X_test[list(model_vars)]\n",
    "        else:  # Intercept-only model\n",
    "            X_train_sub = pd.DataFrame(np.ones(len(X_train)), columns=['Intercept'])\n",
    "            X_test_sub = pd.DataFrame(np.ones(len(X_test)), columns=['Intercept'])\n",
    "        \n",
    "        # Create and fit model\n",
    "        model = LinearRegression(fit_intercept=False)\n",
    "        model.fit(X_train_sub, y_train)\n",
    "        \n",
    "        # Calculate MSEs\n",
    "        train_pred = model.predict(X_train_sub)\n",
    "        test_pred = model.predict(X_test_sub)\n",
    "        train_mse = mean_squared_error(y_train, train_pred)\n",
    "        test_mse = mean_squared_error(y_test, test_pred)\n",
    "        \n",
    "        train_mses.append(train_mse)\n",
    "        test_mses.append(test_mse)\n",
    "    \n",
    "    # Calculate average performance metrics\n",
    "    avg_train_mse = np.mean(train_mses)\n",
    "    avg_test_mse = np.mean(test_mses)\n",
    "    std_test_mse = np.std(test_mses)\n",
    "    \n",
    "    # Store results\n",
    "    results.append({\n",
    "        'Model': f'Model {i}',\n",
    "        'Variables': vars_label,\n",
    "        'Avg Train MSE': avg_train_mse,\n",
    "        'Avg Test MSE': avg_test_mse,\n",
    "        'Test MSE Std': std_test_mse,\n",
    "        'Fold Test MSEs': test_mses\n",
    "    })\n",
    "    \n",
    "    print(f\"Model {i:<2} {vars_label:<35} {avg_train_mse:12.4f} {avg_test_mse:12.4f} {std_test_mse:12.4f}\")\n",
    "\n",
    "# Create sorted DataFrame by average test MSE\n",
    "results_df = pd.DataFrame(results).sort_values('Avg Test MSE').reset_index(drop=True)\n",
    "\n",
    "# Additional insight: Best model based on cross-validation\n",
    "best_model = results_df.iloc[0]\n",
    "print(f\"\\nBest Model: {best_model['Model']} ({best_model['Variables']})\")\n",
    "print(f\"Average Test MSE: {best_model['Avg Test MSE']:.4f} ± {best_model['Test MSE Std']:.4f}\")\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e2088a-af22-4e15-b68d-9d8af88c00d2",
   "metadata": {},
   "source": [
    "#### Calculating Average MSE and SD over five fold CV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550c223c-cec7-4bbe-ac02-58a2d5fed349",
   "metadata": {},
   "source": [
    "**Simulation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6891e4d1-7772-4652-bee5-0ba3c607dae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model    Variables                    Avg MSE    Std Dev\n",
      "-------------------------------------------------------\n",
      "xlist1   Intercept only                9.0850     3.1425\n",
      "xlist2   x1                            5.0581     0.8302\n",
      "xlist3   x2                            6.0673     2.5395\n",
      "xlist4   x3                            6.2800     2.4080\n",
      "xlist5   x1, x2                        2.5739     0.8708\n",
      "xlist6   x2, x3                        3.4631     1.3602\n",
      "xlist7   x1, x3                        3.2917     0.7496\n",
      "xlist8   x1, x2, x3                    0.8416     0.2832\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Set seed and generate data\n",
    "np.random.seed(42)\n",
    "n = 100\n",
    "x1 = np.random.normal(0, 1, n)\n",
    "x2 = np.random.normal(0, 1, n)\n",
    "x3 = np.random.normal(0, 1, n)\n",
    "y = 5 + 2*x1 - 1.5*x2 + 1.2*x3 + np.random.normal(0, 1, n)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({'x1': x1, 'x2': x2, 'x3': x3, 'y': y})\n",
    "\n",
    "# Define all 8 models\n",
    "xlists = [\n",
    "    [],             # xlist1\n",
    "    ['x1'],         # xlist2\n",
    "    ['x2'],         # xlist3\n",
    "    ['x3'],         # xlist4\n",
    "    ['x1', 'x2'],   # xlist5\n",
    "    ['x2', 'x3'],   # xlist6\n",
    "    ['x1', 'x3'],   # xlist7\n",
    "    ['x1', 'x2', 'x3']  # xlist8 (full model)\n",
    "]\n",
    "\n",
    "# KFold settings\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Store results\n",
    "cv_mse_results = []\n",
    "\n",
    "# Loop through each model\n",
    "for i, xlist in enumerate(xlists, 1):\n",
    "    mse_list = []\n",
    "    model = LinearRegression()\n",
    "    \n",
    "    if xlist:\n",
    "        X = df[xlist].values\n",
    "    else:\n",
    "        X = np.ones((df.shape[0], 1))  # Intercept-only model\n",
    "        \n",
    "    y_values = df['y'].values\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y_values[train_index], y_values[test_index]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mse_list.append(mse)\n",
    "    \n",
    "    avg_mse = np.mean(mse_list)\n",
    "    std_mse = np.std(mse_list)\n",
    "    \n",
    "    cv_mse_results.append({\n",
    "        'Model': f'xlist{i}',\n",
    "        'Variables': ', '.join(xlist) if xlist else 'Intercept only',\n",
    "        'Average MSE': round(avg_mse, 4),\n",
    "        'MSE Std Dev': round(std_mse, 4)\n",
    "    })\n",
    "\n",
    "# Display results\n",
    "print(f\"{'Model':<8} {'Variables':<25} {'Avg MSE':>10} {'Std Dev':>10}\")\n",
    "print(\"-\" * 55)\n",
    "for res in cv_mse_results:\n",
    "    print(f\"{res['Model']:<8} {res['Variables']:<25} {res['Average MSE']:10.4f} {res['MSE Std Dev']:10.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839d8d9a-b73c-4921-a9eb-0387119e3a7c",
   "metadata": {},
   "source": [
    "#### Interpretation\n",
    "\n",
    "xlist8 (full model) has the lowest average MSE, as expected (it's the true DGP).\n",
    "\n",
    "Models with only one variable (xlist2, xlist3, etc.) show higher bias and more variance.\n",
    "\n",
    "Standard deviation of MSE across folds helps identify models with stable performance (lower SD preferred).\n",
    "\n",
    "Trade-off is observed: simpler models may have lower variance but higher bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94791ce2-474f-4c8a-b2de-86311fc55254",
   "metadata": {},
   "source": [
    "**Example from NSS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "85b7a699-c402-4148-890d-cf6d0119f6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-Fold Cross-Validation Results\n",
      "Model    Variables                           Avg Train MSE Avg Test MSE Test MSE Std\n",
      "-------------------------------------------------------------------------------------\n",
      "Model 1  Intercept only                      2793346007.2411 2793394861.2272 579964697.8972\n",
      "Model 2  Age                                 2761014863.8667 2761089644.6592 577687814.7197\n",
      "Model 3  Household_Size                      2823728148.0368 2823758196.5639 581903772.7196\n",
      "Model 4  MPCE_Euro                           2736033347.8566 2736179360.3437 567292182.3646\n",
      "Model 5  Age, Household_Size                 2756891757.3790 2757111233.6256 576958828.5947\n",
      "Model 6  Age, MPCE_Euro                      2736025037.1728 2736171050.5307 567292250.5605\n",
      "Model 7  Household_Size, MPCE_Euro           2736033289.5348 2736179302.2171 567292185.6532\n",
      "Model 8  Age, Household_Size, MPCE_Euro      2736024978.7912 2736170992.4012 567292250.6678\n",
      "\n",
      "Summary of 5-Fold Cross-Validation Performance (Sorted by Avg Test MSE):\n",
      "   Model                       Variables    Avg Train MSE     Avg Test MSE  \\\n",
      "0      8  Age, Household_Size, MPCE_Euro 2,736,024,978.79 2,736,170,992.40   \n",
      "1      6                  Age, MPCE_Euro 2,736,025,037.17 2,736,171,050.53   \n",
      "2      7       Household_Size, MPCE_Euro 2,736,033,289.53 2,736,179,302.22   \n",
      "3      4                       MPCE_Euro 2,736,033,347.86 2,736,179,360.34   \n",
      "4      5             Age, Household_Size 2,756,891,757.38 2,757,111,233.63   \n",
      "5      2                             Age 2,761,014,863.87 2,761,089,644.66   \n",
      "6      1                  Intercept only 2,793,346,007.24 2,793,394,861.23   \n",
      "7      3                  Household_Size 2,823,728,148.04 2,823,758,196.56   \n",
      "\n",
      "    Test MSE Std  \n",
      "0 567,292,250.67  \n",
      "1 567,292,250.56  \n",
      "2 567,292,185.65  \n",
      "3 567,292,182.36  \n",
      "4 576,958,828.59  \n",
      "5 577,687,814.72  \n",
      "6 579,964,697.90  \n",
      "7 581,903,772.72  \n",
      "\n",
      "Key Findings:\n",
      "1. Total models evaluated: 8\n",
      "2. Best model: Model 8 (Age, Household_Size, MPCE_Euro)\n",
      "   - Avg Test MSE: 2736170992.4012\n",
      "   - Test MSE Std: 567292250.6678\n",
      "3. Worst model: Model 3 (Household_Size)\n",
      "   - Avg Test MSE: 2823758196.5639\n",
      "4. Performance range: 2736170992.4012 (best) to 2823758196.5639 (worst)\n",
      "\n",
      "Results saved to 'model_comparison_results.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from itertools import combinations\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_stata(r\"D:\\Altaf\\Impact of Insurance on Catastrophic Risk Exposure\\Impact of formal insurance on informal insurance\\Final Dataset 2017.dta\")\n",
    "\n",
    "# Prepare data\n",
    "model_data = df[['In_TotMedicalExp', 'Age', 'Household_Size', 'MPCE_Euro']].dropna()\n",
    "y = model_data['In_TotMedicalExp'].values\n",
    "X = model_data[['Age', 'Household_Size', 'MPCE_Euro']]\n",
    "\n",
    "# Generate all combinations of independent variables\n",
    "variables = list(X.columns)\n",
    "models = []\n",
    "for k in range(0, len(variables) + 1):\n",
    "    for combo in combinations(variables, k):\n",
    "        models.append(list(combo))\n",
    "\n",
    "# Set up KFold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "results = []\n",
    "\n",
    "print(\"5-Fold Cross-Validation Results\")\n",
    "print(f\"{'Model':<8} {'Variables':<35} {'Avg Train MSE':>12} {'Avg Test MSE':>12} {'Test MSE Std':>12}\")\n",
    "print(\"-\" * 85)\n",
    "\n",
    "# Evaluate each model\n",
    "for i, model_vars in enumerate(models, 1):\n",
    "    # Prepare variable names for display\n",
    "    vars_label = ', '.join(model_vars) if model_vars else 'Intercept only'\n",
    "    \n",
    "    # Initialize storage for fold results\n",
    "    train_mses = []\n",
    "    test_mses = []\n",
    "    \n",
    "    # Cross-validation loop\n",
    "    for fold, (train_index, test_index) in enumerate(kf.split(X), 1):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Prepare model data\n",
    "        if model_vars:\n",
    "            X_train_sub = X_train[model_vars]\n",
    "            X_test_sub = X_test[model_vars]\n",
    "        else:  # Intercept-only model\n",
    "            X_train_sub = pd.DataFrame(np.ones(len(X_train)), columns=['Intercept'])\n",
    "            X_test_sub = pd.DataFrame(np.ones(len(X_test)), columns=['Intercept'])\n",
    "        \n",
    "        # Create and fit model\n",
    "        model = LinearRegression(fit_intercept=False)\n",
    "        model.fit(X_train_sub, y_train)\n",
    "        \n",
    "        # Calculate MSEs\n",
    "        train_pred = model.predict(X_train_sub)\n",
    "        test_pred = model.predict(X_test_sub)\n",
    "        train_mse = mean_squared_error(y_train, train_pred)\n",
    "        test_mse = mean_squared_error(y_test, test_pred)\n",
    "        \n",
    "        train_mses.append(train_mse)\n",
    "        test_mses.append(test_mse)\n",
    "    \n",
    "    # Calculate average performance metrics\n",
    "    avg_train_mse = np.mean(train_mses)\n",
    "    avg_test_mse = np.mean(test_mses)\n",
    "    std_test_mse = np.std(test_mses)\n",
    "    \n",
    "    # Store results\n",
    "    results.append({\n",
    "        'Model': i,\n",
    "        'Variables': vars_label,\n",
    "        'Avg Train MSE': avg_train_mse,\n",
    "        'Avg Test MSE': avg_test_mse,\n",
    "        'Test MSE Std': std_test_mse,\n",
    "        'Fold Test MSEs': test_mses\n",
    "    })\n",
    "    \n",
    "    print(f\"Model {i:<2} {vars_label:<35} {avg_train_mse:12.4f} {avg_test_mse:12.4f} {std_test_mse:12.4f}\")\n",
    "\n",
    "# Create sorted DataFrame by average test MSE\n",
    "results_df = pd.DataFrame(results).sort_values('Avg Test MSE').reset_index(drop=True)\n",
    "\n",
    "# Print final results\n",
    "print(\"\\nSummary of 5-Fold Cross-Validation Performance (Sorted by Avg Test MSE):\")\n",
    "print(results_df[['Model', 'Variables', 'Avg Train MSE', 'Avg Test MSE', 'Test MSE Std']])\n",
    "\n",
    "# Additional analysis\n",
    "print(\"\\nKey Findings:\")\n",
    "print(f\"1. Total models evaluated: {len(models)}\")\n",
    "print(f\"2. Best model: Model {results_df.iloc[0]['Model']} ({results_df.iloc[0]['Variables']})\")\n",
    "print(f\"   - Avg Test MSE: {results_df.iloc[0]['Avg Test MSE']:.4f}\")\n",
    "print(f\"   - Test MSE Std: {results_df.iloc[0]['Test MSE Std']:.4f}\")\n",
    "print(f\"3. Worst model: Model {results_df.iloc[-1]['Model']} ({results_df.iloc[-1]['Variables']})\")\n",
    "print(f\"   - Avg Test MSE: {results_df.iloc[-1]['Avg Test MSE']:.4f}\")\n",
    "print(f\"4. Performance range: {results_df['Avg Test MSE'].min():.4f} (best) to {results_df['Avg Test MSE'].max():.4f} (worst)\")\n",
    "\n",
    "# Optional: Save results to CSV\n",
    "results_df.to_csv('model_comparison_results.csv', index=False)\n",
    "print(\"\\nResults saved to 'model_comparison_results.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fff925-d0c6-410e-90e3-a41a39affe50",
   "metadata": {},
   "source": [
    "Cross-validation (CV) offers considerable flexibility, as it can be readily extended beyond ordinary least squares (OLS) estimation to accommodate a range of alternative estimators and loss functions, including the mean absolute error. While information criteria—such as AIC or BIC—are computationally less intensive and thus more practical in certain contexts, they often produce results that are broadly comparable to those derived from CV-based approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b4cc1e-924a-491f-994d-863de9315512",
   "metadata": {},
   "source": [
    "### Leave-One-Out Cross-Validation (LOOCV)\n",
    "\n",
    "Leave-One-Out Cross-Validation (LOOCV) is a special case of *k-fold cross-validation* where the number of folds, *k*, is equal to the number of observations (*n*) in the dataset.\n",
    "\n",
    "That means:\n",
    "\n",
    "- For a dataset with **$n$ observations**, LOOCV performs **$n$ iterations**.\n",
    "- In each iteration:\n",
    "  - **One observation** is held out as the **validation set**.\n",
    "  - The remaining **$n - 1$ observations** are used as the **training set**.\n",
    "- A model is trained on the training set and evaluated on the validation observation.\n",
    "- The process is repeated **$n$ times**, with each observation used exactly once as the validation set.\n",
    "\n",
    "#### Advantages of LOOCV\n",
    "\n",
    "- **Efficient use of data**: Almost the entire dataset is used for training in each iteration.\n",
    "- **Low bias**: Since the training set is nearly the full dataset, the estimate of performance has low bias.\n",
    "- **No randomness**: LOOCV does not rely on random splits; results are deterministic.\n",
    "\n",
    "#### Disadvantages of LOOCV\n",
    "\n",
    "- **High computational cost**: For large datasets, LOOCV requires training the model *n* times.\n",
    "- **High variance**: Since each training set differs by only one observation, the fitted models can be very similar but produce varied validation errors.\n",
    "\n",
    "#### Use Cases\n",
    "\n",
    "- LOOCV is often used when:\n",
    "  - The dataset is **small**, and it's important to retain as much data as possible for training.\n",
    "  - High bias in model performance estimation is a concern.\n",
    "  - Computational resources are **not a major constraint**.\n",
    "\n",
    "#### Python Example: LOOCV with Linear Regression (on Small Dataset)\n",
    "\n",
    "To illustrate LOOCV without heavy computation, we use the **diabetes** dataset from `sklearn` but restrict it to the **first 20 observations** only.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01494cc-e93d-42ea-b959-1efbceb1429c",
   "metadata": {},
   "source": [
    "**Simulation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b2392f5c-53d7-4911-abc8-02fd8f7eed25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MSE (LOOCV): 1789.5769\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Load a small dataset to keep it computationally light\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "X = X[:20]  # using only first 20 samples for simplicity\n",
    "y = y[:20]\n",
    "\n",
    "# Initialize model and LOOCV\n",
    "model = LinearRegression()\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "mse_scores = []\n",
    "\n",
    "# Perform LOOCV\n",
    "for train_index, test_index in loo.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_scores.append(mse)\n",
    "\n",
    "# Average MSE over all LOOCV iterations\n",
    "mean_mse = np.mean(mse_scores)\n",
    "print(f\"Mean MSE (LOOCV): {mean_mse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a387c42-1258-4466-9036-e2609afa7c29",
   "metadata": {},
   "source": [
    "**Example from NSS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4b74d740-deff-4372-8de7-7f4128ab3ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Leave-One-Out Cross-Validation for Full Model...\n",
      "Fold   Test Index   Actual       Predicted    Squared Error  \n",
      "------------------------------------------------------------\n",
      "1      0            0.0000       25586.6875   654678577.2227 \n",
      "50     49           0.0000       19741.7695   389737464.2250 \n",
      "100    99           1175.0000    6048.8584    23754495.6880  \n",
      "150    149          1700.0000    5951.8911    18078578.0392  \n",
      "200    199          0.0000       6756.1108    45645033.6803  \n",
      "250    249          0.0000       13426.5674   180272711.6852 \n",
      "300    299          3800.0000    9467.8320    32124319.9345  \n",
      "350    349          9985.0000    10445.1934   211777.9280    \n",
      "400    399          0.0000       9191.2188    84478502.1104  \n",
      "450    449          700.0000     19741.7539   362588391.8262 \n",
      "500    499          0.0000       15567.0303   242332431.5341 \n",
      "550    549          0.0000       10792.2754   116473208.1071 \n",
      "600    599          9300.0000    18071.7461   76943529.5332  \n",
      "650    649          0.0000       24083.6602   580022686.5217 \n",
      "700    699          0.0000       19741.7617   389737155.7599 \n",
      "750    749          5805.0000    9355.1045    12603241.9054  \n",
      "800    799          5000.0000    15566.9795   111661055.5883 \n",
      "850    849          0.0000       7852.3086    61658750.2515  \n",
      "900    899          0.0000       19741.7617   389737155.7599 \n",
      "950    949          0.0000       19741.7578   389737001.5274 \n",
      "1000   999          1300.0000    18513.8652   296317156.3072 \n",
      "1050   1049         0.0000       15845.3320   251074547.1806 \n",
      "1100   1099         0.0000       13708.6279   187926479.7146 \n",
      "1150   1149         0.0000       9208.7363    84800824.7609  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     27\u001b[39m y_train, y_test = y[train_index], y[test_index]\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Create and fit model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m model = \u001b[43mLinearRegression\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m model.fit(X_train, y_train)\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Make prediction\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:575\u001b[39m, in \u001b[36mLinearRegression.__init__\u001b[39m\u001b[34m(self, fit_intercept, copy_X, tol, n_jobs, positive)\u001b[39m\n\u001b[32m    459\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    460\u001b[39m \u001b[33;03mOrdinary least squares Linear Regression.\u001b[39;00m\n\u001b[32m    461\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    564\u001b[39m \u001b[33;03marray([16.])\u001b[39;00m\n\u001b[32m    565\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    567\u001b[39m _parameter_constraints: \u001b[38;5;28mdict\u001b[39m = {\n\u001b[32m    568\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfit_intercept\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33mboolean\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    569\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcopy_X\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33mboolean\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    572\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtol\u001b[39m\u001b[33m\"\u001b[39m: [Interval(Real, \u001b[32m0\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m, closed=\u001b[33m\"\u001b[39m\u001b[33mleft\u001b[39m\u001b[33m\"\u001b[39m)],\n\u001b[32m    573\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m575\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    576\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    577\u001b[39m     *,\n\u001b[32m    578\u001b[39m     fit_intercept=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    579\u001b[39m     copy_X=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    580\u001b[39m     tol=\u001b[32m1e-6\u001b[39m,\n\u001b[32m    581\u001b[39m     n_jobs=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    582\u001b[39m     positive=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    583\u001b[39m ):\n\u001b[32m    584\u001b[39m     \u001b[38;5;28mself\u001b[39m.fit_intercept = fit_intercept\n\u001b[32m    585\u001b[39m     \u001b[38;5;28mself\u001b[39m.copy_X = copy_X\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_stata(r\"D:\\Altaf\\Impact of Insurance on Catastrophic Risk Exposure\\Impact of formal insurance on informal insurance\\Final Dataset 2017.dta\")\n",
    "\n",
    "# Prepare data\n",
    "model_data = df[['In_TotMedicalExp', 'Age', 'Household_Size', 'MPCE_Euro']].dropna()\n",
    "y = model_data['In_TotMedicalExp'].values\n",
    "X = model_data[['Age', 'Household_Size', 'MPCE_Euro']].values\n",
    "\n",
    "# Initialize LOOCV\n",
    "loo = LeaveOneOut()\n",
    "mse_values = []\n",
    "\n",
    "print(\"Starting Leave-One-Out Cross-Validation for Full Model...\")\n",
    "print(f\"{'Fold':<6} {'Test Index':<12} {'Actual':<12} {'Predicted':<12} {'Squared Error':<15}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# LOOCV process\n",
    "for fold, (train_index, test_index) in enumerate(loo.split(X), 1):\n",
    "    # Split data\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Create and fit model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make prediction\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate squared error\n",
    "    sq_error = (y_test - y_pred) ** 2\n",
    "    mse_values.append(sq_error[0])\n",
    "    \n",
    "    # Print progress for every 50 folds\n",
    "    if fold % 50 == 0 or fold == 1 or fold == len(X):\n",
    "        print(f\"{fold:<6} {test_index[0]:<12} {y_test[0]:<12.4f} {y_pred[0]:<12.4f} {sq_error[0]:<15.4f}\")\n",
    "\n",
    "# Calculate final MSE\n",
    "loo_mse = np.mean(mse_values)\n",
    "loo_mse_std = np.std(mse_values)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Leave-One-Out Cross-Validation Results for Full Model\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total observations: {len(X)}\")\n",
    "print(f\"LOOCV MSE: {loo_mse:.4f}\")\n",
    "print(f\"Standard Deviation of MSE: {loo_mse_std:.4f}\")\n",
    "print(f\"MSE Range: {np.min(mse_values):.4f} - {np.max(mse_values):.4f}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Interpretation and key findings\n",
    "print(\"\\nKey Findings and Interpretation:\")\n",
    "print(\"1. Model Performance:\")\n",
    "print(f\"   - The full model achieved a LOOCV MSE of {loo_mse:.4f}, meaning on average,\")\n",
    "print(f\"     predictions are off by approximately {np.sqrt(loo_mse):.2f} units in medical expenses.\")\n",
    "print(\"\")\n",
    "print(\"2. Model Stability:\")\n",
    "print(f\"   - The standard deviation of {loo_mse_std:.4f} indicates the variability of prediction\")\n",
    "print(\"     errors across different observations.\")\n",
    "print(\"\")\n",
    "print(\"3. Error Distribution:\")\n",
    "print(f\"   - Minimum squared error: {np.min(mse_values):.4f}\")\n",
    "print(f\"   - Maximum squared error: {np.max(mse_values):.4f}\")\n",
    "print(\"   - This range shows how prediction accuracy varies across different households.\")\n",
    "print(\"\")\n",
    "print(\"4. Practical Significance:\")\n",
    "print(\"   - Compared to simpler models (e.g., with fewer predictors), this MSE value\")\n",
    "print(\"     should be evaluated in the context of typical medical expenses in the dataset.\")\n",
    "print(\"   - A good benchmark is to compare this MSE to the variance of medical expenses:\")\n",
    "expense_variance = np.var(y)\n",
    "print(f\"     Variance of medical expenses: {expense_variance:.4f}\")\n",
    "print(f\"     MSE/Variance ratio: {loo_mse/expense_variance:.4f}\")\n",
    "print(\"     (Values closer to 0 indicate better predictive performance)\")\n",
    "print(\"\")\n",
    "print(\"5. Model Selection Insight:\")\n",
    "print(\"   - LOOCV provides an almost unbiased estimate of model performance but is\")\n",
    "print(\"     computationally expensive. This MSE can be directly compared to k-fold CV\")\n",
    "print(\"     results from previous analyses to select the best model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd17a45-f5ea-490f-b9b9-fe57b4911968",
   "metadata": {},
   "source": [
    "**The result is not calculated because of large size of the dataset. For fast iteration it needs significantly more computational power**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8ea90c-15ff-4203-a89b-ec113c0869ad",
   "metadata": {},
   "source": [
    "### Model Selection Techniques in Regression: Best subsets selection and stepwise selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041cc951-9cd1-4349-9262-6b4eea76eef1",
   "metadata": {},
   "source": [
    "#### 1. Best Subsets Selection\n",
    "\n",
    "**Definition:**  \n",
    "Best Subsets Selection is an exhaustive search technique used in regression modeling to identify the most optimal combination of explanatory variables. For a given number of predictors $p$, this method fits all possible $2^p$ combinations of models and evaluates their performance based on certain selection criteria.\n",
    "\n",
    "##### Procedure:\n",
    "1. Consider all possible models involving subsets of the predictors.\n",
    "2. For each possible model size (e.g., 1 variable, 2 variables, ..., p variables), select the best-performing model.\n",
    "3. Compare these best models across model sizes using model selection criteria.\n",
    "\n",
    "##### Model Selection Criteria:\n",
    "- **Adjusted R²**: Adjusts for the number of predictors; higher is better.\n",
    "- **AIC (Akaike Information Criterion)**: Penalizes model complexity; lower is better.\n",
    "- **BIC (Bayesian Information Criterion)**: Stricter penalty for complexity than AIC; lower is better.\n",
    "- **Mallow’s $C_p$**: Ideally close to the number of predictors + 1.\n",
    "- **Cross-Validated MSE**: Average test error; lower is better.\n",
    "\n",
    "##### Advantages:\n",
    "- Identifies the optimal model for each model size.\n",
    "- Provides a comprehensive view of how each subset performs.\n",
    "\n",
    "### Disadvantages:\n",
    "- Computationally intensive: Not feasible for large $p$ (as number of models grows exponentially).\n",
    "- Can be impractical with high-dimensional data.\n",
    "\n",
    "#### 2. Stepwise Selection\n",
    "\n",
    "**Definition:**  \n",
    "Stepwise selection methods apply a greedy algorithm to add or remove predictors from the model based on a predefined criterion (e.g., p-values, AIC, BIC). Unlike best subsets, stepwise selection does not evaluate all possible models.\n",
    "\n",
    "##### Types of Stepwise Methods:\n",
    "\n",
    "###### a. Forward Selection\n",
    "- Starts with no predictors.\n",
    "- Adds one predictor at a time that most improves the model (e.g., largest increase in adjusted R² or largest decrease in AIC).\n",
    "- Continues until no additional predictor improves the model significantly.\n",
    "\n",
    "###### b. Backward Elimination\n",
    "- Starts with the full model (all predictors).\n",
    "- Iteratively removes the least useful predictor (e.g., based on highest p-value).\n",
    "- Stops when all remaining predictors are statistically significant or improve the selection metric.\n",
    "\n",
    "###### c. Stepwise Selection (Bidirectional)\n",
    "- Combines both forward and backward approaches.\n",
    "- At each step, a predictor may be added or removed.\n",
    "- Balances between exploring the model space and computational feasibility.\n",
    "\n",
    "##### Advantages:\n",
    "- Computationally efficient.\n",
    "- Suitable for moderate to large datasets.\n",
    "- Provides reasonable models with lower computational cost.\n",
    "\n",
    "##### Disadvantages:\n",
    "- May converge to a **local optimum**, not the global best model.\n",
    "- Results can be sensitive to the order of predictor inclusion/removal.\n",
    "- Doesn’t explore all possible subsets.\n",
    "\n",
    "#### 3. Summary Comparison\n",
    "\n",
    "| Feature                  | Best Subsets Selection     | Stepwise Selection           |\n",
    "|--------------------------|----------------------------|------------------------------|\n",
    "| Model Space              | Exhaustive ($2^p$ models)    | Greedy (adds/removes one)   |\n",
    "| Computation              | High                       | Moderate                     |\n",
    "| Optimality               | Global                     | May reach local optimum      |\n",
    "| Interpretability         | High                       | Moderate                     |\n",
    "| Feasibility (High p)     | Low                        | High                         |\n",
    "\n",
    "#### 5. Recommendation\n",
    "\n",
    "For small to moderate number of predictors (e.g., $p ≤ 10$), Best Subsets Selection is preferred due to its exhaustive nature. For larger datasets, Stepwise Selection provides a computationally feasible approach with acceptable performance, especially when combined with cross-validation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6105da-0f3c-463b-9191-9e13ab6299f1",
   "metadata": {},
   "source": [
    "#### Best Subsets Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "28fa1926-274b-4a32-a240-ec99d3855d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   n_features                                           features  mse\n",
      "0           5  (MedInc, AveRooms, AveOccup, HouseAge, AveBedrms) 0.64\n",
      "1           4            (MedInc, AveRooms, HouseAge, AveBedrms) 0.64\n",
      "2           4             (MedInc, AveRooms, AveOccup, HouseAge) 0.66\n",
      "3           3                       (MedInc, AveRooms, HouseAge) 0.66\n",
      "4           3                       (MedInc, AveOccup, HouseAge) 0.66\n",
      "5           4            (MedInc, AveOccup, HouseAge, AveBedrms) 0.66\n",
      "6           2                                 (MedInc, HouseAge) 0.66\n",
      "7           3                      (MedInc, HouseAge, AveBedrms) 0.66\n",
      "8           4            (MedInc, AveRooms, AveOccup, AveBedrms) 0.67\n",
      "9           3                      (MedInc, AveRooms, AveBedrms) 0.68\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load California housing dataset\n",
    "california = fetch_california_housing(as_frame=True)\n",
    "X = california.data\n",
    "y = california.target\n",
    "\n",
    "# Use a smaller subset of predictors to speed up\n",
    "selected_features = ['MedInc', 'AveRooms', 'AveOccup', 'HouseAge', 'AveBedrms']\n",
    "X = X[selected_features]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Best subset selection function\n",
    "def best_subset_selection(X_train, y_train, X_test, y_test, max_features=5):\n",
    "    results = []\n",
    "    for k in range(1, max_features + 1):\n",
    "        for subset in itertools.combinations(X_train.columns, k):\n",
    "            X_train_sub = X_train[list(subset)]\n",
    "            X_test_sub = X_test[list(subset)]\n",
    "            model = LinearRegression().fit(X_train_sub, y_train)\n",
    "            y_pred = model.predict(X_test_sub)\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            results.append({\n",
    "                'n_features': k,\n",
    "                'features': subset,\n",
    "                'mse': mse\n",
    "            })\n",
    "    return pd.DataFrame(results).sort_values(by='mse').reset_index(drop=True)\n",
    "\n",
    "# Run the best subset selection\n",
    "subset_results = best_subset_selection(X_train, y_train, X_test, y_test, max_features=5)\n",
    "\n",
    "# Show top 10 performing models\n",
    "print(subset_results.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1979a97c-e7a4-42dc-a4ce-554a056e41f8",
   "metadata": {},
   "source": [
    "**Example from NSS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "75a823ea-be2c-40db-b146-bd2791bbd093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Top Models by Different Selection Criteria\n",
      "======================================================================\n",
      "\n",
      "Top 3 Models by AIC (Lower is Better):\n",
      "                    Predictors  Num_Predictors          AIC\n",
      "                Age, MPCE_Euro               2 2,794,785.06\n",
      "Age, Household_Size, MPCE_Euro               3 2,794,785.68\n",
      "     Household_Size, MPCE_Euro               2 2,796,105.00\n",
      "\n",
      "Top 3 Models by BIC (Lower is Better):\n",
      "                    Predictors  Num_Predictors          BIC\n",
      "                Age, MPCE_Euro               2 2,794,813.98\n",
      "Age, Household_Size, MPCE_Euro               3 2,794,824.25\n",
      "     Household_Size, MPCE_Euro               2 2,796,133.92\n",
      "\n",
      "Top 3 Models by Adjusted R² (Higher is Better):\n",
      "                    Predictors  Num_Predictors  Adj_R2\n",
      "Age, Household_Size, MPCE_Euro               3    0.03\n",
      "                Age, MPCE_Euro               2    0.03\n",
      "     Household_Size, MPCE_Euro               2    0.02\n",
      "\n",
      "Top 3 Models by Mallow's Cp (Cp ≈ p is Best):\n",
      "                    Predictors  Num_Predictors   Cp\n",
      "Age, Household_Size, MPCE_Euro               3 4.00\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Consensus Best Model Analysis\n",
      "======================================================================\n",
      "\n",
      "Top Consensus Models (Most Frequently Selected):\n",
      "1. Age, Household_Size, MPCE_Euro (Score: 4/4)\n",
      "2. Age, MPCE_Euro (Score: 3/4)\n",
      "3. Household_Size, MPCE_Euro (Score: 3/4)\n",
      "\n",
      "Recommended Model: Age, Household_Size, MPCE_Euro\n",
      "Rationale: Selected as best by the most selection criteria\n",
      "Model Parameters:\n",
      "                    Predictors  Num_Predictors          AIC          BIC  Adj_R2   Cp                    RSS\n",
      "Age, Household_Size, MPCE_Euro               3 2,794,785.68 2,794,824.25    0.03 4.00 307,113,762,062,991.50\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from itertools import combinations\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_stata(r\"D:\\Altaf\\Impact of Insurance on Catastrophic Risk Exposure\\Impact of formal insurance on informal insurance\\Final Dataset 2017.dta\")\n",
    "\n",
    "# Prepare data\n",
    "model_data = df[['In_TotMedicalExp', 'Age', 'Household_Size', 'MPCE_Euro']].dropna()\n",
    "y = model_data['In_TotMedicalExp']\n",
    "X = model_data[['Age', 'Household_Size', 'MPCE_Euro']]\n",
    "n = len(y)\n",
    "\n",
    "# Generate all predictor combinations\n",
    "variables = X.columns.tolist()\n",
    "models = []\n",
    "for k in range(0, len(variables) + 1):\n",
    "    for combo in combinations(variables, k):\n",
    "        models.append(list(combo))\n",
    "\n",
    "# Fit full model for Mallow's Cp reference\n",
    "X_full = sm.add_constant(X)\n",
    "model_full = sm.OLS(y, X_full).fit()\n",
    "sigma2_full = model_full.mse_resid\n",
    "\n",
    "# Evaluate all models\n",
    "results = []\n",
    "for model_vars in models:\n",
    "    # Prepare design matrix\n",
    "    if model_vars:\n",
    "        X_design = sm.add_constant(X[list(model_vars)])\n",
    "    else:\n",
    "        # CORRECTED: Properly create intercept-only design matrix\n",
    "        X_design = pd.DataFrame(np.ones(len(X)), columns=['const'])\n",
    "    \n",
    "    # Fit model\n",
    "    model = sm.OLS(y, X_design).fit()\n",
    "    p = X_design.shape[1]  # Number of parameters\n",
    "    k = len(model_vars)     # Number of predictors\n",
    "    rss = model.ssr         # Residual sum of squares\n",
    "    \n",
    "    # Calculate metrics\n",
    "    aic = model.aic\n",
    "    bic = model.bic\n",
    "    adj_r2 = model.rsquared_adj\n",
    "    cp = (rss / sigma2_full) - n + 2 * p\n",
    "    \n",
    "    results.append({\n",
    "        'Predictors': ', '.join(model_vars) if model_vars else \"Intercept Only\",\n",
    "        'Num_Predictors': k,\n",
    "        'AIC': aic,\n",
    "        'BIC': bic,\n",
    "        'Adj_R2': adj_r2,\n",
    "        'Cp': cp,\n",
    "        'RSS': rss\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Find top models by each criterion\n",
    "top_aic = results_df.sort_values('AIC').head(3)\n",
    "top_bic = results_df.sort_values('BIC').head(3)\n",
    "top_adjr2 = results_df.sort_values('Adj_R2', ascending=False).head(3)\n",
    "top_cp = results_df[results_df['Cp'] <= results_df['Num_Predictors'] + 1].sort_values('Cp').head(3)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"Top Models by Different Selection Criteria\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nTop 3 Models by AIC (Lower is Better):\")\n",
    "print(top_aic[['Predictors', 'Num_Predictors', 'AIC']].to_string(index=False))\n",
    "\n",
    "print(\"\\nTop 3 Models by BIC (Lower is Better):\")\n",
    "print(top_bic[['Predictors', 'Num_Predictors', 'BIC']].to_string(index=False))\n",
    "\n",
    "print(\"\\nTop 3 Models by Adjusted R² (Higher is Better):\")\n",
    "print(top_adjr2[['Predictors', 'Num_Predictors', 'Adj_R2']].to_string(index=False))\n",
    "\n",
    "print(\"\\nTop 3 Models by Mallow's Cp (Cp ≈ p is Best):\")\n",
    "print(top_cp[['Predictors', 'Num_Predictors', 'Cp']].to_string(index=False))\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# AIC Plot\n",
    "plt.subplot(2, 2, 1)\n",
    "for k, group in results_df.groupby('Num_Predictors'):\n",
    "    plt.scatter(group['Num_Predictors'], group['AIC'], alpha=0.6, label=f'{k} predictors')\n",
    "plt.scatter(top_aic['Num_Predictors'], top_aic['AIC'], color='red', s=100, label='Top Models')\n",
    "plt.title('AIC by Number of Predictors')\n",
    "plt.xlabel('Number of Predictors')\n",
    "plt.ylabel('AIC')\n",
    "plt.grid(True)\n",
    "\n",
    "# BIC Plot\n",
    "plt.subplot(2, 2, 2)\n",
    "for k, group in results_df.groupby('Num_Predictors'):\n",
    "    plt.scatter(group['Num_Predictors'], group['BIC'], alpha=0.6)\n",
    "plt.scatter(top_bic['Num_Predictors'], top_bic['BIC'], color='red', s=100)\n",
    "plt.title('BIC by Number of Predictors')\n",
    "plt.xlabel('Number of Predictors')\n",
    "plt.ylabel('BIC')\n",
    "plt.grid(True)\n",
    "\n",
    "# Adj R² Plot\n",
    "plt.subplot(2, 2, 3)\n",
    "for k, group in results_df.groupby('Num_Predictors'):\n",
    "    plt.scatter(group['Num_Predictors'], group['Adj_R2'], alpha=0.6)\n",
    "plt.scatter(top_adjr2['Num_Predictors'], top_adjr2['Adj_R2'], color='red', s=100)\n",
    "plt.title('Adjusted R² by Number of Predictors')\n",
    "plt.xlabel('Number of Predictors')\n",
    "plt.ylabel('Adjusted R²')\n",
    "plt.grid(True)\n",
    "\n",
    "# Cp Plot\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot([0, 3], [0, 3], 'k--', label='Ideal Cp = p')  # Reference line\n",
    "for k, group in results_df.groupby('Num_Predictors'):\n",
    "    plt.scatter(group['Num_Predictors'], group['Cp'], alpha=0.6)\n",
    "plt.scatter(top_cp['Num_Predictors'], top_cp['Cp'], color='red', s=100)\n",
    "plt.title(\"Mallow's Cp by Number of Predictors\")\n",
    "plt.xlabel('Number of Predictors')\n",
    "plt.ylabel(\"Mallow's Cp\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('best_subset_selection.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Identify consensus best model\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Consensus Best Model Analysis\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create scoring system\n",
    "model_scores = {}\n",
    "for i, row in results_df.iterrows():\n",
    "    score = 0\n",
    "    if row['Predictors'] in top_aic['Predictors'].values: score += 1\n",
    "    if row['Predictors'] in top_bic['Predictors'].values: score += 1\n",
    "    if row['Predictors'] in top_adjr2['Predictors'].values: score += 1\n",
    "    if row['Predictors'] in top_cp['Predictors'].values: score += 1\n",
    "    model_scores[row['Predictors']] = score\n",
    "\n",
    "# Get top 3 consensus models\n",
    "top_consensus = sorted(model_scores.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "print(\"\\nTop Consensus Models (Most Frequently Selected):\")\n",
    "for i, (model, score) in enumerate(top_consensus, 1):\n",
    "    print(f\"{i}. {model} (Score: {score}/4)\")\n",
    "\n",
    "# Final recommendation\n",
    "best_model = top_consensus[0][0]\n",
    "print(f\"\\nRecommended Model: {best_model}\")\n",
    "print(\"Rationale: Selected as best by the most selection criteria\")\n",
    "print(\"Model Parameters:\")\n",
    "print(results_df[results_df['Predictors'] == best_model].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b5a2ba-16e9-4cab-b423-b9d5b7bbf06e",
   "metadata": {},
   "source": [
    "### Foward and Backward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9e0a64-75eb-48d1-a852-584b29b77d09",
   "metadata": {},
   "source": [
    "#### Overview of Selection Methods\n",
    "\n",
    "- **Forward Selection**: Begins with no predictors and adds variables one by one, selecting the variable that results in the best model improvement at each step.\n",
    "- **Backward Elimination**: Starts with all predictors and removes one at a time, eliminating the variable whose removal least harms the model’s performance.\n",
    "\n",
    "Both approaches aim to balance predictive accuracy (measured using Mean Squared Error, MSE) and model simplicity (fewer predictors).\n",
    "\n",
    "#### Forward Selection\n",
    "\n",
    "| Step | Features                             | MSE   |\n",
    "|------|--------------------------------------|--------|\n",
    "| 1    | ['MedInc']                           | 0.72   |\n",
    "| 2    | ['MedInc', 'AveRooms']               | 0.66   |\n",
    "| 3    | ['MedInc', 'AveRooms', 'HouseAge']   | 0.64   |\n",
    "| 4    | ['MedInc', 'AveRooms', 'HouseAge', 'AveOccup'] | 0.64   |\n",
    "\n",
    "**Key Points**:\n",
    "- The first variable (`MedInc`) contributes most to prediction accuracy.\n",
    "- Adding `AveRooms` significantly improves model performance.\n",
    "- Beyond 3–4 variables, improvement in MSE is minimal.\n",
    "- Forward selection yields a relatively simple model with competitive MSE.\n",
    "\n",
    "#### Backward Elimination\n",
    "\n",
    "| Step | Features                             | MSE   |\n",
    "|------|--------------------------------------|--------|\n",
    "| 0    | All features                         | 0.65   |\n",
    "| 1    | [All except 'Latitude']              | 0.64   |\n",
    "| 2    | [All except 'Latitude', 'AveBedrms'] | 0.63   |\n",
    "| 3    | [Reduced to top 5]                   | 0.64   |\n",
    "\n",
    "**Key Points**:\n",
    "- Removing redundant predictors (e.g., `Latitude`, `AveBedrms`) improves model performance.\n",
    "- MSE improves slightly as irrelevant predictors are eliminated.\n",
    "- After a point, further reduction may slightly increase MSE, indicating possible underfitting.\n",
    "\n",
    "#### Final Comparison\n",
    "\n",
    "| Method              | Best Model Size | Best MSE | Comment                                                                 |\n",
    "|---------------------|------------------|----------|-------------------------------------------------------------------------|\n",
    "| Forward Selection   | 3–4 features      | ~0.64    | Simpler, interpretable, and efficient.                                 |\n",
    "| Backward Elimination| 6–8 features      | ~0.63    | Slightly better accuracy, but more complex and possibly overfit.       |\n",
    "\n",
    "#### Conclusion\n",
    "\n",
    "- **Forward selection** is preferable when interpretability and parsimony are desired.\n",
    "- **Backward elimination** may be better if minimizing prediction error is the only goal.\n",
    "- The best model depends on the specific use case: interpretability vs. predictive performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02886b1-5f13-4ee5-a620-e49b40a1ece8",
   "metadata": {},
   "source": [
    "**Simulation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ac11562d-534d-45a6-ab46-32e1fbf26b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward Selection Results:\n",
      "                                            features  mse\n",
      "0                                           [MedInc] 0.71\n",
      "1                                 [MedInc, HouseAge] 0.66\n",
      "2                       [MedInc, HouseAge, Latitude] 0.65\n",
      "3            [MedInc, HouseAge, Latitude, Longitude] 0.55\n",
      "4  [MedInc, HouseAge, Latitude, Longitude, AveOccup] 0.55\n",
      "5  [MedInc, HouseAge, Latitude, Longitude, AveOcc... 0.55\n",
      "6  [MedInc, HouseAge, Latitude, Longitude, AveOcc... 0.55\n",
      "\n",
      "Backward Elimination Results:\n",
      "                                            features  mse\n",
      "0  [MedInc, HouseAge, AveRooms, AveBedrms, Popula... 0.56\n",
      "1  [MedInc, HouseAge, AveRooms, Population, AveOc... 0.55\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 2: Load Dataset\n",
    "housing = fetch_california_housing()\n",
    "X = pd.DataFrame(housing.data, columns=housing.feature_names)\n",
    "y = housing.target\n",
    "\n",
    "# Step 3: Split Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Forward Selection\n",
    "def forward_selection(X_train, y_train, X_test, y_test):\n",
    "    remaining_features = list(X_train.columns)\n",
    "    selected_features = []\n",
    "    best_mse = float(\"inf\")\n",
    "    results = []\n",
    "\n",
    "    while remaining_features:\n",
    "        mse_with_candidates = []\n",
    "        for candidate in remaining_features:\n",
    "            features_to_test = selected_features + [candidate]\n",
    "            model = LinearRegression()\n",
    "            model.fit(X_train[features_to_test], y_train)\n",
    "            y_pred = model.predict(X_test[features_to_test])\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            mse_with_candidates.append((mse, candidate))\n",
    "\n",
    "        mse_with_candidates.sort()\n",
    "        best_new_mse, best_candidate = mse_with_candidates[0]\n",
    "\n",
    "        if best_new_mse < best_mse:\n",
    "            remaining_features.remove(best_candidate)\n",
    "            selected_features.append(best_candidate)\n",
    "            best_mse = best_new_mse\n",
    "            results.append({\n",
    "                'features': selected_features.copy(),\n",
    "                'mse': best_mse\n",
    "            })\n",
    "        else:\n",
    "            break  # Stop if no improvement\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Step 5: Backward Selection\n",
    "\n",
    "def backward_elimination(X_train, y_train, X_test, y_test):\n",
    "    selected_features = list(X_train.columns)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train[selected_features], y_train)\n",
    "    y_pred = model.predict(X_test[selected_features])\n",
    "    best_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    results = [{'features': selected_features.copy(), 'mse': best_mse}]\n",
    "\n",
    "    while len(selected_features) > 1:\n",
    "        mse_with_candidates = []\n",
    "        for candidate in selected_features:\n",
    "            features_to_test = [f for f in selected_features if f != candidate]\n",
    "            model = LinearRegression()\n",
    "            model.fit(X_train[features_to_test], y_train)\n",
    "            y_pred = model.predict(X_test[features_to_test])\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            mse_with_candidates.append((mse, candidate))\n",
    "\n",
    "        mse_with_candidates.sort()\n",
    "        best_new_mse, worst_feature = mse_with_candidates[0]\n",
    "\n",
    "        if best_new_mse < best_mse:\n",
    "            selected_features.remove(worst_feature)\n",
    "            best_mse = best_new_mse\n",
    "            results.append({\n",
    "                'features': selected_features.copy(),\n",
    "                'mse': best_mse\n",
    "            })\n",
    "        else:\n",
    "            break  # Stop if removing worsens performance\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Step 6.1: Forward Selection\n",
    "forward_results = forward_selection(X_train, y_train, X_test, y_test)\n",
    "print(\"Forward Selection Results:\")\n",
    "print(forward_results)\n",
    "\n",
    "# Step 6.2: Backward Elimination\n",
    "backward_results = backward_elimination(X_train, y_train, X_test, y_test)\n",
    "print(\"\\nBackward Elimination Results:\")\n",
    "print(backward_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95386e86-45c0-43f3-834f-72ffcf657f70",
   "metadata": {},
   "source": [
    "**Example from NSS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ac5819b6-576c-4426-9048-339b8d294c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Forward Stepwise Selection Process\n",
      "======================================================================\n",
      "\n",
      "Forward Selection Steps:\n",
      "Step  Added           AIC             Adj R²         \n",
      "1     MPCE_Euro       2796233.52      0.0217         \n",
      "2     Age             2794785.06      0.0340         \n",
      "\n",
      "======================================================================\n",
      "Backward Elimination Process\n",
      "======================================================================\n",
      "\n",
      "Backward Elimination Steps:\n",
      "Step  Features                                 AIC             Adj R²          Worst Feature   P-value   \n",
      "3     Age, Household_Size, MPCE_Euro           2794785.68      0.0340          Household_Size  0.2401\n",
      "2     Age, MPCE_Euro                           2794785.06      0.0340          Age             0.0000\n",
      "\n",
      "======================================================================\n",
      "Model Comparison\n",
      "======================================================================\n",
      "Metric               Forward Selection    Backward Elimination\n",
      "Features             MPCE_Euro, Age       Age, MPCE_Euro      \n",
      "AIC                  2794785.06           2794785.06          \n",
      "BIC                  2794813.98           2794813.98          \n",
      "Adj R²               0.0340               0.0340              \n",
      "MSE (Test)           2115473619.7607      2115473619.7607     \n",
      "\n",
      "======================================================================\n",
      "Best Model Recommendation\n",
      "======================================================================\n",
      "Recommended by: Backward Elimination\n",
      "Features: Age, MPCE_Euro\n",
      "AIC: 2794785.06\n",
      "BIC: 2794813.98\n",
      "Adj R²: 0.0340\n",
      "Test MSE: 2115473619.7607\n",
      "\n",
      "Model Summary:\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       In_TotMedicalExp   R-squared:                       0.034\n",
      "Model:                            OLS   Adj. R-squared:                  0.034\n",
      "Method:                 Least Squares   F-statistic:                     2007.\n",
      "Date:                Fri, 01 Aug 2025   Prob (F-statistic):               0.00\n",
      "Time:                        16:38:19   Log-Likelihood:            -1.3974e+06\n",
      "No. Observations:              113823   AIC:                         2.795e+06\n",
      "Df Residuals:                  113820   BIC:                         2.795e+06\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const      -1.705e+04    586.676    -29.057      0.000   -1.82e+04   -1.59e+04\n",
      "Age          424.0792     11.100     38.206      0.000     402.324     445.835\n",
      "MPCE_Euro      2.9663      0.059     49.867      0.000       2.850       3.083\n",
      "==============================================================================\n",
      "Omnibus:                   261846.693   Durbin-Watson:                   1.881\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):       6739091642.832\n",
      "Skew:                          21.942   Prob(JB):                         0.00\n",
      "Kurtosis:                    1194.233   Cond. No.                     1.67e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.67e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_stata(r\"D:\\Altaf\\Impact of Insurance on Catastrophic Risk Exposure\\Impact of formal insurance on informal insurance\\Final Dataset 2017.dta\")\n",
    "\n",
    "# Prepare data\n",
    "model_data = df[['In_TotMedicalExp', 'Age', 'Household_Size', 'MPCE_Euro']].dropna()\n",
    "y = model_data['In_TotMedicalExp']\n",
    "X = model_data[['Age', 'Household_Size', 'MPCE_Euro']]\n",
    "\n",
    "# Add constant for statsmodels\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Split data for validation (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "def forward_selection(X, y, significance_level=0.05):\n",
    "    \"\"\"\n",
    "    Perform forward stepwise regression\n",
    "    \"\"\"\n",
    "    initial_features = X.columns.tolist()\n",
    "    if 'const' in initial_features:\n",
    "        initial_features.remove('const')\n",
    "    selected_features = []\n",
    "    current_score, best_new_score = float('inf'), float('inf')\n",
    "    history = []\n",
    "    \n",
    "    while initial_features and current_score == best_new_score:\n",
    "        scores_with_candidates = []\n",
    "        for candidate in initial_features:\n",
    "            features = ['const'] + selected_features + [candidate]\n",
    "            model = sm.OLS(y, X[features]).fit()\n",
    "            score = model.aic\n",
    "            scores_with_candidates.append((score, candidate, model, features))\n",
    "        \n",
    "        # Sort candidates by AIC\n",
    "        scores_with_candidates.sort(key=lambda x: x[0])\n",
    "        best_new_score, best_candidate, best_model, best_features = scores_with_candidates[0]\n",
    "        \n",
    "        if best_new_score < current_score:\n",
    "            initial_features.remove(best_candidate)\n",
    "            selected_features.append(best_candidate)\n",
    "            current_score = best_new_score\n",
    "            history.append({\n",
    "                'step': len(selected_features),\n",
    "                'added': best_candidate,\n",
    "                'aic': best_new_score,\n",
    "                'rsquared_adj': best_model.rsquared_adj,\n",
    "                'model': best_model,\n",
    "                'features': best_features\n",
    "            })\n",
    "    \n",
    "    # Final model with selected features\n",
    "    final_features = ['const'] + selected_features\n",
    "    final_model = sm.OLS(y, X[final_features]).fit()\n",
    "    return history, final_model, final_features\n",
    "\n",
    "def backward_elimination(X, y, significance_level=0.05):\n",
    "    \"\"\"\n",
    "    Perform backward stepwise regression\n",
    "    \"\"\"\n",
    "    features = X.columns.tolist()\n",
    "    history = []\n",
    "    \n",
    "    while len(features) > 1:  # Keep constant\n",
    "        model = sm.OLS(y, X[features]).fit()\n",
    "        \n",
    "        # Get p-values (exclude constant)\n",
    "        pvalues = model.pvalues\n",
    "        if 'const' in pvalues:\n",
    "            pvalues = pvalues.drop('const')\n",
    "        \n",
    "        if pvalues.empty:\n",
    "            break\n",
    "            \n",
    "        max_pvalue = pvalues.max()\n",
    "        worst_feature = pvalues.idxmax()\n",
    "        \n",
    "        history.append({\n",
    "            'step': len(features) - 1,\n",
    "            'current_features': features.copy(),\n",
    "            'aic': model.aic,\n",
    "            'rsquared_adj': model.rsquared_adj,\n",
    "            'worst_feature': worst_feature,\n",
    "            'max_pvalue': max_pvalue\n",
    "        })\n",
    "        \n",
    "        if max_pvalue > significance_level:\n",
    "            features.remove(worst_feature)\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    final_model = sm.OLS(y, X[features]).fit()\n",
    "    return history, final_model, features\n",
    "\n",
    "# Perform forward selection\n",
    "print(\"=\"*70)\n",
    "print(\"Forward Stepwise Selection Process\")\n",
    "print(\"=\"*70)\n",
    "forward_history, forward_model, forward_features = forward_selection(X, y)\n",
    "\n",
    "# Print forward selection steps\n",
    "print(\"\\nForward Selection Steps:\")\n",
    "print(f\"{'Step':<5} {'Added':<15} {'AIC':<15} {'Adj R²':<15}\")\n",
    "for step in forward_history:\n",
    "    print(f\"{step['step']:<5} {step['added']:<15} {step['aic']:<15.2f} {step['rsquared_adj']:<15.4f}\")\n",
    "\n",
    "# Perform backward elimination\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Backward Elimination Process\")\n",
    "print(\"=\"*70)\n",
    "backward_history, backward_model, backward_features = backward_elimination(X, y)\n",
    "\n",
    "# Print backward elimination steps\n",
    "print(\"\\nBackward Elimination Steps:\")\n",
    "print(f\"{'Step':<5} {'Features':<40} {'AIC':<15} {'Adj R²':<15} {'Worst Feature':<15} {'P-value':<10}\")\n",
    "for step in backward_history:\n",
    "    feat_str = ', '.join([f for f in step['current_features'] if f != 'const'])\n",
    "    print(f\"{step['step']:<5} {feat_str:<40} {step['aic']:<15.2f} {step['rsquared_adj']:<15.4f} \"\n",
    "          f\"{step['worst_feature']:<15} {step['max_pvalue']:.4f}\")\n",
    "\n",
    "# Prepare test sets with correct features\n",
    "X_test_forward = X_test[forward_features]\n",
    "X_test_backward = X_test[backward_features]\n",
    "\n",
    "# Calculate test MSE\n",
    "forward_test_mse = mean_squared_error(y_test, forward_model.predict(X_test_forward))\n",
    "backward_test_mse = mean_squared_error(y_test, backward_model.predict(X_test_backward))\n",
    "\n",
    "# Compare final models\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Model Comparison\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Metric':<20} {'Forward Selection':<20} {'Backward Elimination':<20}\")\n",
    "print(f\"{'Features':<20} {', '.join([f for f in forward_features if f != 'const']):<20} \"\n",
    "      f\"{', '.join([f for f in backward_features if f != 'const']):<20}\")\n",
    "print(f\"{'AIC':<20} {forward_model.aic:<20.2f} {backward_model.aic:<20.2f}\")\n",
    "print(f\"{'BIC':<20} {forward_model.bic:<20.2f} {backward_model.bic:<20.2f}\")\n",
    "print(f\"{'Adj R²':<20} {forward_model.rsquared_adj:<20.4f} {backward_model.rsquared_adj:<20.4f}\")\n",
    "print(f\"{'MSE (Test)':<20} {forward_test_mse:<20.4f} {backward_test_mse:<20.4f}\")\n",
    "\n",
    "# Determine best model\n",
    "if forward_model.aic < backward_model.aic:\n",
    "    best_model = forward_model\n",
    "    best_features = forward_features\n",
    "    method = \"Forward Selection\"\n",
    "else:\n",
    "    best_model = backward_model\n",
    "    best_features = backward_features\n",
    "    method = \"Backward Elimination\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Best Model Recommendation\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Recommended by: {method}\")\n",
    "print(f\"Features: {', '.join([f for f in best_features if f != 'const'])}\")\n",
    "print(f\"AIC: {best_model.aic:.2f}\")\n",
    "print(f\"BIC: {best_model.bic:.2f}\")\n",
    "print(f\"Adj R²: {best_model.rsquared_adj:.4f}\")\n",
    "print(f\"Test MSE: {mean_squared_error(y_test, best_model.predict(X_test[best_features])):.4f}\")\n",
    "print(\"\\nModel Summary:\")\n",
    "print(best_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "85a371a4-6d96-4900-9f0a-1b7714699410",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook ML_1-Predictive_Ability.ipynb to latex\n",
      "[NbConvertApp] Support files will be in ML_1-Predictive_Ability_files\\\n",
      "[NbConvertApp] Making directory ML_1-Predictive_Ability_files\n",
      "[NbConvertApp] Writing 247169 bytes to ML_1-Predictive_Ability.tex\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert ML_1-Predictive_Ability.ipynb --to latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1675b9c0-5822-4767-94ed-c4bb8f99e81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!xelatex ML_1-Predictive_Ability.tex -quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f51407-9b76-4db7-98aa-159ecd866300",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (Updated)",
   "language": "python",
   "name": "py312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
